{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sandrun","text":"<p>Anonymous, ephemeral, sandboxed code execution service</p> <p>Sandrun provides secure, isolated code execution without user accounts or data persistence. Submit code, get results, everything auto-deletes. Simple, private, secure.</p>"},{"location":"#what-is-sandrun","title":"What is Sandrun?","text":"<p>Sandrun is a lightweight batch job execution system that runs untrusted code in hardware-enforced isolation. Built on Linux security primitives (namespaces, seccomp-BPF, cgroups), it provides:</p> <ul> <li>True anonymity: No signup, no authentication, no user tracking</li> <li>Complete isolation: Each job runs in its own sandbox with restricted syscalls</li> <li>Automatic cleanup: All data lives in RAM and auto-deletes after use</li> <li>Fair resource sharing: IP-based rate limiting prevents abuse while ensuring access</li> <li>Multi-language support: Python, JavaScript, Bash, Ruby, R, and more</li> <li>Production-ready: Distributed execution via pool coordinator, signed results, WebSocket streaming</li> </ul> <p>Perfect for ephemeral compute needs, privacy-preserving analysis, untrusted code execution, and distributed batch processing.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#privacy-security","title":"Privacy &amp; Security","text":"<ul> <li>\ud83d\udd12 Hardware-enforced Sandbox - Linux namespaces, seccomp-BPF syscall filtering, capability dropping</li> <li>\ud83c\udfad Anonymous by Design - No accounts, no tracking, IP-based quotas only</li> <li>\ud83d\udca8 Memory-only Execution - All data in tmpfs (RAM), never touches disk</li> <li>\ud83d\udd10 Cryptographic Verification - Ed25519 signatures for worker identity and result authenticity</li> <li>\ud83d\udeaa No Network Access - Jobs are completely airgapped during execution</li> </ul>"},{"location":"#developer-experience","title":"Developer Experience","text":"<ul> <li>\ud83d\ude80 Fast &amp; Lightweight - Native C++ implementation, &lt;10ms startup time, minimal overhead</li> <li>\ud83c\udf10 Multi-language - Python, Node.js, Bash, Ruby, R, and more</li> <li>\ud83d\udce6 Multi-file Projects - Submit tarballs with dependencies, auto-install requirements</li> <li>\u26a1 Simple REST API - Submit via HTTP POST, poll for status, download outputs</li> <li>\ud83c\udfaf Pre-built Environments - ml-basic, vision, nlp, data-science templates with common packages</li> </ul>"},{"location":"#scalability-integration","title":"Scalability &amp; Integration","text":"<ul> <li>\ud83d\udd17 Pool Coordinator - Distribute jobs across multiple workers with health checking and load balancing</li> <li>\ud83d\udce1 WebSocket Streaming - Real-time log streaming during execution</li> <li>\ud83e\udd16 MCP Server Integration - Give Claude and other LLMs safe code execution capabilities</li> <li>\ud83d\udcca Job Broker - SQLite-backed job queue for distributed compute</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Install dependencies\nsudo apt-get install libseccomp-dev libcap-dev libssl-dev\n\n# Build\ncmake -B build\ncmake --build build\n\n# Run server (requires root for namespaces)\nsudo ./build/sandrun --port 8443\n</code></pre>"},{"location":"#submit-your-first-job","title":"Submit Your First Job","text":"<pre><code># Create a simple Python script\necho 'print(\"Hello, Sandrun!\")' &gt; hello.py\n\n# Package and submit\ntar czf job.tar.gz hello.py\ncurl -X POST http://localhost:8443/submit \\\n  -F \"files=@job.tar.gz\" \\\n  -F 'manifest={\"entrypoint\":\"hello.py\",\"interpreter\":\"python3\"}'\n\n# Response:\n# {\"job_id\":\"job-abc123\",\"status\":\"queued\"}\n\n# Check status\ncurl http://localhost:8443/status/job-abc123\n\n# Get logs\ncurl http://localhost:8443/logs/job-abc123\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#for-individuals","title":"For Individuals","text":"<ul> <li>Privacy-Preserving Analysis - Process sensitive data without leaving traces</li> <li>Testing Untrusted Code - Run code from the internet safely in isolation</li> <li>Quick Prototyping - Execute code snippets without local environment setup</li> <li>Learning &amp; Education - Experiment with code in a safe sandbox</li> </ul>"},{"location":"#for-teams-organizations","title":"For Teams &amp; Organizations","text":"<ul> <li>Distributed Batch Processing - Scale compute across multiple workers</li> <li>CI/CD Pipeline Integration - Execute test suites or build jobs in isolated environments</li> <li>Anonymous Job Submission - Process user-submitted code without authentication overhead</li> <li>Multi-tenant Compute - Provide code execution as a service with strong isolation</li> </ul>"},{"location":"#for-ai-llm-integration","title":"For AI &amp; LLM Integration","text":"<ul> <li>AI Code Execution - Let LLMs like Claude execute code safely via MCP protocol</li> <li>Data Analysis Workflows - Enable AI assistants to run pandas, numpy, or R code</li> <li>Automated Testing - LLMs can test their own generated code</li> </ul>"},{"location":"#real-world-examples","title":"Real-World Examples","text":"<p>Quick Python Script</p> <pre><code># Create a simple analysis script\necho 'import statistics; print(statistics.mean([1,2,3,4,5]))' &gt; analyze.py\n\n# Package and submit\ntar czf job.tar.gz analyze.py\ncurl -X POST http://localhost:8443/submit \\\n  -F \"files=@job.tar.gz\" \\\n  -F 'manifest={\"entrypoint\":\"analyze.py\",\"interpreter\":\"python3\"}'\n\n# Output: {\"job_id\":\"job-abc123\",\"status\":\"queued\"}\n</code></pre> <p>Multi-file ML Project</p> <pre><code># Project structure:\n# project/\n# \u251c\u2500\u2500 train.py\n# \u251c\u2500\u2500 model.py\n# \u251c\u2500\u2500 data.csv\n# \u2514\u2500\u2500 requirements.txt\n\ntar czf project.tar.gz -C project .\ncurl -X POST http://localhost:8443/submit \\\n  -F \"files=@project.tar.gz\" \\\n  -F 'manifest={\n    \"entrypoint\":\"train.py\",\n    \"interpreter\":\"python3\",\n    \"requirements\":\"requirements.txt\",\n    \"outputs\":[\"model.pkl\",\"metrics.json\"],\n    \"timeout\":600,\n    \"memory_mb\":1024\n  }'\n</code></pre> <p>Real-time Log Streaming</p> <pre><code>// Watch logs in real-time via WebSocket\nconst ws = new WebSocket('ws://localhost:8443/logs/job-abc123/stream');\nws.onmessage = (event) =&gt; {\n  console.log(event.data);  // Prints logs as they happen\n};\n</code></pre>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph LR\n    A[Client] --&gt;|HTTP POST| B[Sandrun Server]\n    B --&gt;|Queue| C[Job Queue]\n    C --&gt;|Execute| D[Sandbox]\n    D --&gt;|Isolated| E[Linux Namespaces]\n    D --&gt;|Filter| F[Seccomp-BPF]\n    D --&gt;|Limit| G[Cgroups]\n    D --&gt;|Results| H[tmpfs RAM]\n    H --&gt;|Download| A\n    H --&gt;|Auto-delete| I[Cleanup]\n</code></pre> <p>Core Components:</p> <ul> <li>HTTP Server: Minimal C++ HTTP/1.1 server with multipart upload support</li> <li>Job Queue: FIFO queue with IP-based rate limiting and priority handling</li> <li>Sandbox: Linux namespace isolation with seccomp syscall filtering</li> <li>Resource Manager: Cgroup-based CPU/memory limits with automatic enforcement</li> <li>Worker Identity: Ed25519 cryptographic signing for result verification</li> <li>Pool Coordinator: Distributed job routing across trusted worker nodes</li> </ul> <p>Learn more about the architecture \u2192</p>"},{"location":"#security-model","title":"Security Model","text":"<p>Security Boundaries</p> <p>Sandrun provides strong isolation for untrusted code execution but relies on the Linux kernel. Always run on updated systems with kernel security patches.</p> <p>What Sandrun Protects Against: - Filesystem access outside the sandbox - Network access from jobs - Process interference between jobs - Memory disclosure between jobs - Persistence of job data after completion</p> <p>What Sandrun Does NOT Protect Against: - Kernel vulnerabilities (keep your kernel updated!) - Timing attacks between concurrent jobs - Covert channels via CPU cache timing - Physical hardware attacks</p> <p>Read the full security model \u2192</p>"},{"location":"#performance-characteristics","title":"Performance Characteristics","text":"Metric Value Job startup time &lt;10ms Overhead per job &lt;1% CPU Memory footprint 10MB (server) + 512MB (per job) Throughput 100+ jobs/second API latency &lt;50ms (submit/status)"},{"location":"#next-steps","title":"Next Steps","text":""},{"location":"#new-users","title":"New Users","text":"<ol> <li>Getting Started Guide - Install, configure, and run your first job</li> <li>API Reference - Complete REST API documentation</li> <li>Job Manifest - Configure job execution parameters</li> </ol>"},{"location":"#advanced-usage","title":"Advanced Usage","text":"<ol> <li>Trusted Pool - Distribute jobs across multiple workers</li> <li>MCP Server - Give Claude AI safe code execution</li> <li>Job Broker - SQLite-backed distributed job queue</li> </ol>"},{"location":"#developers","title":"Developers","text":"<ol> <li>Architecture - Understand the design and security model</li> <li>Building - Compile from source and contribute</li> <li>Testing - Run tests and verify functionality</li> </ol>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>GitHub: github.com/yourusername/sandrun</li> <li>Issues: Report bugs, request features, ask questions</li> <li>Discussions: Share use cases and best practices</li> <li>Contributions: Pull requests welcome! See CONTRIBUTING.md</li> </ul>"},{"location":"#license","title":"License","text":"<p>Sandrun is open source under the MIT License.</p> <p>Free to use, modify, and distribute - See LICENSE for details.</p> <p>Ready to get started? Install Sandrun \u2192</p>"},{"location":"CONTRIBUTING_TO_DOCS/","title":"Sandrun Documentation","text":"<p>This directory contains the source files for Sandrun's documentation, built using MkDocs with the Material theme.</p>"},{"location":"CONTRIBUTING_TO_DOCS/#quick-start","title":"Quick Start","text":""},{"location":"CONTRIBUTING_TO_DOCS/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install mkdocs-material mkdocs-minify-plugin\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#local-development","title":"Local Development","text":"<pre><code># Serve documentation locally with live reload\nmkdocs serve\n\n# Open in browser: http://127.0.0.1:8000\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#build-documentation","title":"Build Documentation","text":"<pre><code># Build static site\nmkdocs build\n\n# Output: site/ directory\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#deploy-to-github-pages","title":"Deploy to GitHub Pages","text":"<pre><code># One-time deploy\nmkdocs gh-deploy\n\n# Or use automated deployment via GitHub Actions\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#documentation-structure","title":"Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                    # Homepage\n\u251c\u2500\u2500 getting-started.md          # Installation and first job\n\u251c\u2500\u2500 api-reference.md            # REST API documentation\n\u251c\u2500\u2500 job-manifest.md             # Job configuration reference\n\u251c\u2500\u2500 architecture.md             # System design and internals\n\u251c\u2500\u2500 faq.md                      # Frequently asked questions\n\u251c\u2500\u2500 security.md                 # Security guide and best practices\n\u251c\u2500\u2500 troubleshooting.md          # Common issues and solutions\n\u2502\n\u251c\u2500\u2500 integrations/               # Integration guides\n\u2502   \u251c\u2500\u2500 trusted-pool.md        # Pool coordinator\n\u2502   \u251c\u2500\u2500 broker.md              # Job broker\n\u2502   \u2514\u2500\u2500 mcp-server.md          # Claude AI integration\n\u2502\n\u251c\u2500\u2500 development/                # Developer guides\n\u2502   \u251c\u2500\u2500 building.md            # Build from source\n\u2502   \u2514\u2500\u2500 testing.md             # Testing guide\n\u2502\n\u2514\u2500\u2500 images/                     # Diagrams and screenshots\n    \u2514\u2500\u2500 (add your images here)\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#documentation-guidelines","title":"Documentation Guidelines","text":""},{"location":"CONTRIBUTING_TO_DOCS/#writing-style","title":"Writing Style","text":"<ul> <li>Use clear, concise language</li> <li>Write in second person (\"you can\", not \"one can\")</li> <li>Use active voice where possible</li> <li>Include code examples for all features</li> <li>Add warnings for security-critical information</li> </ul>"},{"location":"CONTRIBUTING_TO_DOCS/#code-examples","title":"Code Examples","text":"<p>Use syntax highlighting:</p> <pre><code>```python\nimport requests\nresponse = requests.get('http://localhost:8443/')\n```\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#admonitions","title":"Admonitions","text":"<p>Use Material theme admonitions for important information:</p> <pre><code>!!! tip \"Performance Tip\"\n    Use environment templates to avoid installing dependencies every time.\n\n!!! warning \"Security Warning\"\n    Always keep your kernel updated for security patches.\n\n!!! example \"Example: Submit Job\"\n    ```bash\n    curl -X POST http://localhost:8443/submit \\\n      -F \"files=@job.tar.gz\"\n    ```\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#tables","title":"Tables","text":"<p>Use tables for structured data:</p> <pre><code>| Feature | Value |\n|---------|-------|\n| CPU Quota | 10 seconds/minute |\n| Memory | 512MB per job |\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#links","title":"Links","text":"<p>Internal links (relative): <pre><code>See the [API Reference](api-reference.md) for details.\n</code></pre></p> <p>External links: <pre><code>Check out [MkDocs](https://www.mkdocs.org/) for more info.\n</code></pre></p>"},{"location":"CONTRIBUTING_TO_DOCS/#adding-new-pages","title":"Adding New Pages","text":"<ol> <li>Create the Markdown file in <code>docs/</code></li> <li>Add to navigation in <code>mkdocs.yml</code>:    <pre><code>nav:\n  - New Page: new-page.md\n</code></pre></li> <li>Test locally: <code>mkdocs serve</code></li> <li>Commit and push</li> </ol>"},{"location":"CONTRIBUTING_TO_DOCS/#using-diagrams","title":"Using Diagrams","text":""},{"location":"CONTRIBUTING_TO_DOCS/#mermaid-diagrams","title":"Mermaid Diagrams","text":"<p>Mermaid is supported out of the box:</p> <pre><code>```mermaid\ngraph LR\n    A[Client] --&gt; B[Server]\n    B --&gt; C[Sandbox]\n```\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#static-images","title":"Static Images","text":"<ol> <li>Add images to <code>docs/images/</code></li> <li>Reference in Markdown:    <pre><code>![Architecture Diagram](images/architecture.svg)\n</code></pre></li> </ol> <p>See the repository root for <code>DIAGRAM_SUGGESTIONS.md</code> with diagram ideas.</p>"},{"location":"CONTRIBUTING_TO_DOCS/#configuration","title":"Configuration","text":"<p>Documentation configuration is in <code>mkdocs.yml</code>:</p> <ul> <li>Theme settings: Material theme customization</li> <li>Navigation: Page ordering and structure</li> <li>Plugins: Search, minify, etc.</li> <li>Extensions: Markdown extensions enabled</li> </ul>"},{"location":"CONTRIBUTING_TO_DOCS/#testing-documentation","title":"Testing Documentation","text":""},{"location":"CONTRIBUTING_TO_DOCS/#check-for-broken-links","title":"Check for Broken Links","text":"<pre><code># Build in strict mode (fails on warnings)\nmkdocs build --strict\n\n# Check for broken links\nfind docs/ -name \"*.md\" -exec grep -H \"](.*)\" {} \\; | grep \"http\"\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#preview-on-mobile","title":"Preview on Mobile","text":"<pre><code># Serve on all interfaces\nmkdocs serve -a 0.0.0.0:8000\n\n# Access from mobile on same network\n# http://&lt;your-ip&gt;:8000\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#automated-deployment","title":"Automated Deployment","text":"<p>Documentation is automatically deployed via GitHub Actions on push to <code>master</code>.</p> <p>See <code>.github/workflows/docs.yml</code> for configuration.</p>"},{"location":"CONTRIBUTING_TO_DOCS/#versioning","title":"Versioning","text":"<p>To add versioned documentation:</p> <pre><code># Install mike\npip install mike\n\n# Deploy version\nmike deploy v1.0 latest -u\n\n# Set default version\nmike set-default latest\n\n# Deploy to GitHub Pages\nmike deploy --push --update-aliases v1.0 latest\n</code></pre>"},{"location":"CONTRIBUTING_TO_DOCS/#seo-optimization","title":"SEO Optimization","text":"<ul> <li>Each page has a unique title (H1)</li> <li>Use descriptive headings (H2, H3)</li> <li>Include meta descriptions in frontmatter:   <pre><code>---\ndescription: Complete API reference for Sandrun REST endpoints\n---\n</code></pre></li> <li>Use descriptive link text (not \"click here\")</li> </ul>"},{"location":"CONTRIBUTING_TO_DOCS/#accessibility","title":"Accessibility","text":"<ul> <li>Use proper heading hierarchy (H1 \u2192 H2 \u2192 H3)</li> <li>Add alt text to images</li> <li>Ensure code examples are readable</li> <li>Test with screen readers if possible</li> </ul>"},{"location":"CONTRIBUTING_TO_DOCS/#contributing","title":"Contributing","text":"<p>To contribute to documentation:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch: <code>git checkout -b docs/your-feature</code></li> <li>Make changes and test locally</li> <li>Build in strict mode: <code>mkdocs build --strict</code></li> <li>Submit pull request</li> </ol>"},{"location":"CONTRIBUTING_TO_DOCS/#review-checklist","title":"Review Checklist","text":"<ul> <li>[ ] Spelling and grammar checked</li> <li>[ ] Code examples tested and working</li> <li>[ ] Links verified (no 404s)</li> <li>[ ] Builds without warnings: <code>mkdocs build --strict</code></li> <li>[ ] Renders correctly in browser</li> <li>[ ] Mobile-friendly (test with <code>mkdocs serve</code>)</li> </ul>"},{"location":"CONTRIBUTING_TO_DOCS/#getting-help","title":"Getting Help","text":"<ul> <li>MkDocs Documentation: https://www.mkdocs.org/</li> <li>Material Theme: https://squidfunk.github.io/mkdocs-material/</li> <li>Markdown Guide: https://www.markdownguide.org/</li> </ul>"},{"location":"CONTRIBUTING_TO_DOCS/#license","title":"License","text":"<p>Documentation is licensed under the same license as Sandrun (MIT).</p> <p>Happy documenting! \ud83d\udcda</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete REST API documentation for Sandrun's HTTP interface.</p>"},{"location":"api-reference/#overview","title":"Overview","text":"<p>Sandrun provides a simple REST API for anonymous code execution. All endpoints return JSON responses (except for file downloads and logs).</p>"},{"location":"api-reference/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8443\n</code></pre> <p>Protocol Support</p> <ul> <li>Production deployments should use HTTPS with valid certificates</li> <li>CORS is enabled by default for web frontend support</li> <li>WebSocket support available for log streaming</li> </ul>"},{"location":"api-reference/#authentication","title":"Authentication","text":"<p>None required! Sandrun is anonymous by design. Rate limiting is based on client IP address only.</p>"},{"location":"api-reference/#response-format","title":"Response Format","text":"<p>All successful API responses follow this structure:</p> <pre><code>{\n  \"job_id\": \"unique-identifier\",\n  \"status\": \"queued|running|completed|failed\",\n  \"...\": \"additional fields\"\n}\n</code></pre> <p>Error responses:</p> <pre><code>{\n  \"error\": \"Human-readable error message\",\n  \"details\": \"Additional context (optional)\",\n  \"retry_after\": 30  // For rate limiting (optional)\n}\n</code></pre>"},{"location":"api-reference/#quick-reference","title":"Quick Reference","text":"Method Endpoint Purpose GET <code>/</code> Server info and status POST <code>/submit</code> Submit new job GET <code>/status/{job_id}</code> Get job status and metadata GET <code>/logs/{job_id}</code> Get job stdout/stderr WS <code>/logs/{job_id}/stream</code> Stream logs in real-time GET <code>/outputs/{job_id}</code> List output files GET <code>/download/{job_id}/{path}</code> Download output file GET <code>/stats</code> Check quota and system stats GET <code>/environments</code> List available environments GET <code>/health</code> Health check (for pools)"},{"location":"api-reference/#endpoints","title":"Endpoints","text":""},{"location":"api-reference/#get","title":"GET /","text":"<p>Get server information and status.</p> <p>Response:</p> <pre><code>{\n  \"service\": \"sandrun\",\n  \"status\": \"running\",\n  \"description\": \"Batch job execution with directory upload\",\n  \"privacy\": \"Jobs auto-delete after download\",\n  \"limits\": \"10 CPU-sec/min, 512MB RAM, 5 min timeout\"\n}\n</code></pre>"},{"location":"api-reference/#post-submit","title":"POST /submit","text":"<p>Submit a new job for execution.</p> <p>Request:</p> <p>Multipart form data: - <code>files</code>: Tarball containing job files (<code>.tar.gz</code>) - <code>manifest</code>: JSON manifest (see Job Manifest)</p> <p>Example:</p> <pre><code>curl -X POST http://localhost:8443/submit \\\n  -F \"files=@project.tar.gz\" \\\n  -F 'manifest={\"entrypoint\":\"main.py\",\"interpreter\":\"python3\"}'\n</code></pre> <p>Response:</p> <pre><code>{\n  \"job_id\": \"job-abc123def456\",\n  \"status\": \"queued\",\n  \"position\": 3\n}\n</code></pre> <p>Status Codes:</p> <ul> <li><code>200 OK</code> - Job accepted</li> <li><code>400 Bad Request</code> - Invalid manifest or files</li> <li><code>429 Too Many Requests</code> - Rate limit exceeded</li> </ul>"},{"location":"api-reference/#get-statusjob_id","title":"GET /status/{job_id}","text":"<p>Get job execution status and metadata.</p> <p>Response:</p> <pre><code>{\n  \"job_id\": \"job-abc123def456\",\n  \"status\": \"completed\",\n  \"execution_metadata\": {\n    \"cpu_seconds\": 1.23,\n    \"memory_peak_bytes\": 52428800,\n    \"exit_code\": 0,\n    \"environment\": \"default\"\n  },\n  \"job_hash\": \"sha256-hash-of-inputs\",\n  \"output_files\": {\n    \"result.txt\": {\n      \"path\": \"result.txt\",\n      \"size_bytes\": 1024,\n      \"sha256_hash\": \"abc123...\",\n      \"type\": \"file\"\n    }\n  },\n  \"worker_metadata\": {\n    \"worker_id\": \"base64-encoded-public-key\",\n    \"signature\": \"base64-encoded-signature\"\n  }\n}\n</code></pre> <p>Job Status Values:</p> <ul> <li><code>queued</code> - Waiting in queue</li> <li><code>running</code> - Currently executing</li> <li><code>completed</code> - Finished successfully</li> <li><code>failed</code> - Execution failed</li> </ul>"},{"location":"api-reference/#get-logsjob_id","title":"GET /logs/{job_id}","text":"<p>Get job stdout and stderr logs.</p> <p>Response:</p> <p>Plain text output from job execution.</p> <p>Example:</p> <pre><code>curl http://localhost:8443/logs/job-abc123def456\n</code></pre> <pre><code>Hello from Sandrun!\nProcessing data...\nResults saved to result.txt\n</code></pre>"},{"location":"api-reference/#websocket-logsjob_idstream","title":"WebSocket /logs/{job_id}/stream","text":"<p>Stream logs in real-time via WebSocket.</p> <p>Example (JavaScript):</p> <pre><code>const ws = new WebSocket('ws://localhost:8443/logs/job-abc123def456/stream');\n\nws.onmessage = (event) =&gt; {\n  console.log(event.data);\n};\n</code></pre>"},{"location":"api-reference/#get-outputsjob_id","title":"GET /outputs/{job_id}","text":"<p>List available output files for download.</p> <p>Response:</p> <pre><code>{\n  \"job_id\": \"job-abc123def456\",\n  \"outputs\": [\n    {\n      \"path\": \"result.txt\",\n      \"size_bytes\": 1024,\n      \"type\": \"file\"\n    },\n    {\n      \"path\": \"images/\",\n      \"type\": \"directory\",\n      \"files\": [\"plot1.png\", \"plot2.png\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"api-reference/#get-downloadjob_idfilepath","title":"GET /download/{job_id}/{filepath}","text":"<p>Download a specific output file.</p> <p>Example:</p> <pre><code>curl http://localhost:8443/download/job-abc123/result.txt -o result.txt\n</code></pre> <p>Response:</p> <p>Binary file content with appropriate <code>Content-Type</code> header.</p>"},{"location":"api-reference/#get-stats","title":"GET /stats","text":"<p>Get quota information and system statistics.</p> <p>Response:</p> <pre><code>{\n  \"your_quota\": {\n    \"used\": 2.5,\n    \"limit\": 10.0,\n    \"available\": 7.5,\n    \"active_jobs\": 1,\n    \"can_submit\": true,\n    \"reason\": \"\"\n  },\n  \"system\": {\n    \"queue_length\": 3,\n    \"active_jobs\": 5\n  }\n}\n</code></pre>"},{"location":"api-reference/#get-environments","title":"GET /environments","text":"<p>List available pre-built environments.</p> <p>Response:</p> <pre><code>{\n  \"templates\": [\n    \"default\",\n    \"ml-basic\",\n    \"vision\",\n    \"nlp\",\n    \"data-science\",\n    \"scientific\"\n  ],\n  \"stats\": {\n    \"total_templates\": 6,\n    \"cached_environments\": 3,\n    \"total_uses\": 42,\n    \"disk_usage_mb\": 512\n  }\n}\n</code></pre>"},{"location":"api-reference/#get-health","title":"GET /health","text":"<p>Health check endpoint (for pool coordinators).</p> <p>Response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"worker_id\": \"base64-encoded-public-key\"\n}\n</code></pre>"},{"location":"api-reference/#rate-limits","title":"Rate Limits","text":""},{"location":"api-reference/#per-ip-limits","title":"Per-IP Limits","text":"<ul> <li>CPU Quota: 10 CPU-seconds per minute</li> <li>Concurrent Jobs: 2 jobs maximum</li> <li>Hourly Jobs: 20 jobs per hour</li> </ul>"},{"location":"api-reference/#per-job-limits","title":"Per-Job Limits","text":"<ul> <li>Memory: 512MB RAM maximum</li> <li>Timeout: 5 minutes maximum</li> <li>Storage: 100MB in tmpfs</li> </ul>"},{"location":"api-reference/#rate-limit-response","title":"Rate Limit Response","text":"<p>When rate limited:</p> <pre><code>{\n  \"error\": \"Rate limit exceeded\",\n  \"reason\": \"CPU quota exhausted (10.2/10.0 seconds used)\",\n  \"retry_after\": 45\n}\n</code></pre>"},{"location":"api-reference/#error-responses","title":"Error Responses","text":"<p>All errors follow this format:</p> <pre><code>{\n  \"error\": \"Error message\",\n  \"details\": \"Additional information\"\n}\n</code></pre>"},{"location":"api-reference/#common-errors","title":"Common Errors","text":"<p>400 Bad Request:</p> <pre><code>{\n  \"error\": \"Invalid manifest\",\n  \"details\": \"Missing required field: entrypoint\"\n}\n</code></pre> <p>404 Not Found:</p> <pre><code>{\n  \"error\": \"Job not found\",\n  \"details\": \"job-xyz789\"\n}\n</code></pre> <p>429 Too Many Requests:</p> <pre><code>{\n  \"error\": \"Rate limit exceeded\",\n  \"reason\": \"Too many concurrent jobs (2/2)\",\n  \"retry_after\": 60\n}\n</code></pre> <p>500 Internal Server Error:</p> <pre><code>{\n  \"error\": \"Internal server error\",\n  \"details\": \"Failed to create sandbox\"\n}\n</code></pre>"},{"location":"api-reference/#authentication_1","title":"Authentication","text":"<p>Sandrun is anonymous by default. No API keys or authentication required.</p> <p>For trusted pool deployments, workers authenticate via Ed25519 public keys.</p>"},{"location":"api-reference/#cors","title":"CORS","text":"<p>CORS is enabled for all origins to support web frontends.</p>"},{"location":"api-reference/#content-types","title":"Content Types","text":"<p>Request: - <code>multipart/form-data</code> for <code>/submit</code></p> <p>Response: - <code>application/json</code> for most endpoints - <code>text/plain</code> for <code>/logs/{job_id}</code> - <code>application/octet-stream</code> for <code>/download/{job_id}/{file}</code></p>"},{"location":"api-reference/#examples","title":"Examples","text":""},{"location":"api-reference/#submit-and-wait-for-completion","title":"Submit and Wait for Completion","text":"<pre><code>#!/bin/bash\n\n# Submit job\nRESPONSE=$(curl -s -X POST http://localhost:8443/submit \\\n  -F \"files=@job.tar.gz\" \\\n  -F 'manifest={\"entrypoint\":\"main.py\",\"interpreter\":\"python3\"}')\n\nJOB_ID=$(echo $RESPONSE | jq -r '.job_id')\necho \"Job ID: $JOB_ID\"\n\n# Poll until complete\nwhile true; do\n  STATUS=$(curl -s http://localhost:8443/status/$JOB_ID | jq -r '.status')\n  echo \"Status: $STATUS\"\n\n  if [ \"$STATUS\" = \"completed\" ] || [ \"$STATUS\" = \"failed\" ]; then\n    break\n  fi\n\n  sleep 2\ndone\n\n# Get logs\ncurl http://localhost:8443/logs/$JOB_ID\n</code></pre>"},{"location":"api-reference/#stream-logs-in-real-time","title":"Stream Logs in Real-Time","text":"<pre><code>import websocket\n\ndef on_message(ws, message):\n    print(message, end='')\n\nws = websocket.WebSocketApp(\n    \"ws://localhost:8443/logs/job-abc123/stream\",\n    on_message=on_message\n)\n\nws.run_forever()\n</code></pre>"},{"location":"api-reference/#download-all-outputs","title":"Download All Outputs","text":"<pre><code>#!/bin/bash\n\nJOB_ID=\"job-abc123\"\n\n# Get output list\nOUTPUTS=$(curl -s http://localhost:8443/outputs/$JOB_ID | jq -r '.outputs[].path')\n\n# Download each file\nfor OUTPUT in $OUTPUTS; do\n  curl -o \"$OUTPUT\" \"http://localhost:8443/download/$JOB_ID/$OUTPUT\"\n  echo \"Downloaded: $OUTPUT\"\ndone\n</code></pre>"},{"location":"api-reference/#client-libraries","title":"Client Libraries","text":""},{"location":"api-reference/#python","title":"Python","text":"<pre><code>from integrations.python_client.sandrun_client import SandrunClient\n\nclient = SandrunClient(\"http://localhost:8443\")\n\n# Submit and wait\nresult = client.run_and_wait(\n    code=\"print('Hello!')\",\n    interpreter=\"python3\"\n)\n\nprint(result['logs']['stdout'])\n</code></pre>"},{"location":"api-reference/#javascript","title":"JavaScript","text":"<p>See <code>integrations/web-frontend/</code> for a complete web client example.</p>"},{"location":"api-reference/#curl","title":"cURL","text":"<p>See <code>integrations/examples/curl_examples.sh</code> for command-line examples.</p>"},{"location":"api-reference/#next-steps","title":"Next Steps","text":"<ul> <li>Job Manifest - Configure job execution</li> <li>Getting Started - Setup and first job</li> <li>Integrations - Extend capabilities</li> </ul>"},{"location":"architecture/","title":"Sandrun: Anonymous Ephemeral Code Execution","text":""},{"location":"architecture/#motivation","title":"Motivation","text":""},{"location":"architecture/#the-problem","title":"The Problem","text":"<p>Modern computing is increasingly locked down. Running arbitrary code requires: - Creating accounts on cloud platforms (identity exposure) - Installing complex development environments (system contamination) - Trusting third-party services with your code (privacy violation) - Managing dependencies and credentials (operational burden)</p> <p>Meanwhile, there's a legitimate need for ephemeral computation: - Testing code snippets without contaminating your system - Running untrusted scripts safely - Sharing computational resources anonymously - Quick data processing without infrastructure</p>"},{"location":"architecture/#the-vision","title":"The Vision","text":"<p>Sandrun provides anonymous, ephemeral, sandboxed code execution with these principles:</p> <ol> <li>No Identity: No accounts, no tracking, no persistence beyond job lifetime</li> <li>True Isolation: Hardware-enforced sandboxing via Linux security primitives</li> <li>Privacy by Design: Code and data exist only in memory, auto-destroyed after use</li> <li>Fair Access: Rate limiting by IP ensures equitable resource sharing</li> <li>Simplicity: Single binary, minimal dependencies, clear security model</li> </ol>"},{"location":"architecture/#theory","title":"Theory","text":""},{"location":"architecture/#privacy-model","title":"Privacy Model","text":"<p>Threat Model: - Server admin should learn minimal information about executed code - Network observers should see only encrypted traffic - Other users should have zero visibility into your jobs - System compromise shouldn't leak historical job data</p> <p>Privacy Guarantees: - Jobs execute in isolated namespaces (PID, network, mount, IPC, UTS) - Memory is never swapped to disk (mlocked pages) - All job data stored in tmpfs (RAM only) - Automatic destruction after job completion - No logging of job contents, only resource metrics</p>"},{"location":"architecture/#security-architecture","title":"Security Architecture","text":"<p>Defense in Depth: 1. Network Layer: TLS only, no HTTP fallback 2. Application Layer: Minimal HTTP server, no dynamic content 3. Execution Layer: Separate sandboxed process per job 4. System Layer: Seccomp-BPF syscall filtering 5. Hardware Layer: CPU/memory quotas via cgroups</p> <p>Sandbox Constraints (Per Job): <pre><code>- New PID namespace (job can't see other processes)\n- New network namespace (isolated network stack)\n- New mount namespace (private filesystem view)\n- Seccomp filter (whitelist of ~50 safe syscalls)\n- No capability privileges (drops all capabilities)\n- Read-only root filesystem bind mount\n- tmpfs for /tmp and working directory\n- CPU quota: 10 seconds per minute\n- Memory limit: 512MB\n- No network access (airgapped execution)\n</code></pre></p>"},{"location":"architecture/#rate-limiting-theory","title":"Rate Limiting Theory","text":"<p>Fair Queuing with Time-Based Quotas:</p> <p>Instead of traditional rate limiting (requests/second), we implement CPU-time fairness: - Each IP gets 10 CPU-seconds per minute - Maximum 2 concurrent jobs per IP - Jobs queued when quota exhausted</p> <p>This ensures: - Long-running jobs don't block others - Burst capacity for quick scripts - Natural DOS protection - Fair resource distribution</p>"},{"location":"architecture/#practice","title":"Practice","text":""},{"location":"architecture/#implementation-stack","title":"Implementation Stack","text":"<p>Why C++: - Direct syscall access for sandboxing - Predictable memory management (no GC pauses) - Small binary size (~500KB vs 50MB+ for Python) - Native seccomp-bpf and namespace support - Compile-time security checks</p> <p>Minimal Dependencies: <pre><code>System Libraries Only:\n- libseccomp: Syscall filtering\n- libcap: Capability management  \n- pthread: Threading\n- Standard C++ library\n\nNo External Dependencies:\n- HTTP parsing: Hand-rolled minimal parser\n- JSON: Simple struct serialization\n- Crypto: Use kernel's /dev/urandom\n</code></pre></p>"},{"location":"architecture/#api-design","title":"API Design","text":"<p>Batch Job Submission: <pre><code>POST /submit\n  Content-Type: multipart/form-data\n  Body: Files (tar.gz, zip, or individual files) + manifest\n  Returns: {\"job_id\": \"uuid\", \"status\": \"queued\"}\n\nGET /status/{job_id}\n  Returns: {\n    \"status\": \"queued|running|completed|failed\",\n    \"queue_position\": 3,\n    \"metrics\": {\"cpu_seconds\": 1.23, \"memory_mb\": 128}\n  }\n\nGET /logs/{job_id}\n  Returns: {\"stdout\": \"...\", \"stderr\": \"...\"}\n\nGET /outputs/{job_id}\n  Returns: {\"files\": [\"results/data.csv\", \"plot.png\"]}\n\nGET /download/{job_id}\n  Returns: tar.gz of output files matching manifest patterns\n  Auto-deletes after retrieval\n</code></pre></p> <p>No Complexity: - No authentication/authorization - No persistent storage - No configuration - Simple multipart parsing (minimal code) - No external dependencies</p>"},{"location":"architecture/#operational-model","title":"Operational Model","text":"<p>Single Binary Deployment: <pre><code># Build\ncmake -B build &amp;&amp; cmake --build build\n\n# Run (needs CAP_SYS_ADMIN for namespaces)\nsudo setcap cap_sys_admin+ep ./sandrun\n./sandrun --port 8443 --cert cert.pem --key key.pem\n</code></pre></p> <p>Auto-Cleanup: - Jobs older than 5 minutes: Killed - Completed jobs: Deleted after 1 minute - Failed jobs: Deleted immediately - Memory usage &gt; 80%: Oldest jobs evicted</p>"},{"location":"architecture/#performance-targets","title":"Performance Targets","text":"<p>Design Goals: - Startup time: &lt;10ms per job - Overhead: &lt;1% CPU for orchestration - Memory: &lt;10MB for service, 512MB per job - Latency: &lt;50ms to start execution - Throughput: 100+ jobs/second on modern hardware</p>"},{"location":"architecture/#security-considerations","title":"Security Considerations","text":"<p>What We Explicitly Don't Protect Against: - Timing attacks between jobs (shared CPU) - Resource exhaustion within quotas - Covert channels via cache timing - Kernel vulnerabilities (requires kernel hardening)</p> <p>What We Do Protect Against: - Code injection/execution outside sandbox - Filesystem access beyond tmpfs - Network access from jobs - Process visibility across jobs - Memory disclosure between jobs - Persistence of any job data</p>"},{"location":"architecture/#architecture-frontendbackend-separation","title":"Architecture: Frontend/Backend Separation","text":""},{"location":"architecture/#backend-c-sandbox-service","title":"Backend (C++ Sandbox Service)","text":"<p>Responsibilities: - Secure code execution - Resource management - Rate limiting - Minimal HTTP API</p> <p>Why C++: - Direct syscall control for sandboxing - Predictable memory management - Minimal attack surface - No interpreter overhead</p>"},{"location":"architecture/#frontend-separate-application","title":"Frontend (Separate Application)","text":"<p>Responsibilities: - User interface - Code editing - Result visualization - API interaction</p> <p>Why Separate: - Security isolation from sandbox - Independent deployment/updates - Technology freedom (Python/JS/etc) - CDN hosting possible - Multiple frontends can coexist</p>"},{"location":"architecture/#frontend-options","title":"Frontend Options","text":"<p>1. Python + Streamlit (Recommended for beauty) <pre><code># frontend.py - Beautiful UI in minutes\nimport streamlit as st\nimport requests\n\nst.title(\"\ud83c\udfc3 Sandrun - Anonymous Code Execution\")\n\ncode = st.text_area(\"Code\", height=300)\nlang = st.selectbox(\"Language\", [\"python\", \"javascript\", \"bash\"])\n\nif st.button(\"Run\", type=\"primary\"):\n    with st.spinner(\"Executing...\"):\n        res = requests.post(API_URL, json={\n            \"code\": code,\n            \"interpreter\": lang\n        })\n        st.code(res.json()[\"output\"])\n</code></pre></p> <p>2. Static HTML + JS (Recommended for simplicity) <pre><code>&lt;!-- index.html - Single file, no build needed --&gt;\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;style&gt;/* Minimal CSS */&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;textarea id=\"code\"&gt;&lt;/textarea&gt;\n    &lt;button onclick=\"runCode()\"&gt;Run&lt;/button&gt;\n    &lt;pre id=\"output\"&gt;&lt;/pre&gt;\n    &lt;script&gt;\n        async function runCode() {\n            const res = await fetch('/run', {\n                method: 'POST',\n                body: document.getElementById('code').value\n            });\n            document.getElementById('output').textContent = \n                await res.text();\n        }\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre></p> <p>3. CLI Tool (For developers) <pre><code># sandrun CLI\necho 'print(\"hello\")' | sandrun --lang python\nsandrun script.py\nsandrun --watch script.js  # Re-run on changes\n</code></pre></p>"},{"location":"architecture/#usage-examples","title":"Usage Examples","text":"<pre><code># Direct API Usage\ncurl -X POST https://api.sandrun.io/run \\\n  -H \"Content-Type: text/plain\" \\\n  -d 'print(\"Hello from sandbox\")'\n\n# Via Streamlit Frontend\nstreamlit run frontend.py\n\n# Via Static HTML\npython -m http.server 8080  # Serve index.html\n\n# Via CLI\nsandrun my_script.py\n</code></pre>"},{"location":"architecture/#future-considerations","title":"Future Considerations","text":"<p>Possible Enhancements (Keeping Simplicity): - WebAssembly runtime for additional isolation - Encrypted job storage with ephemeral keys - Distributed execution across multiple nodes - Optional result encryption with client-provided key</p> <p>Explicitly Not Planned: - User accounts or authentication - Persistent storage - Complex job dependencies - File upload/download beyond code - Rich API with many endpoints</p>"},{"location":"architecture/#conclusion","title":"Conclusion","text":"<p>Sandrun represents a return to Unix philosophy: do one thing well. It executes code anonymously and ephemerally with strong isolation. No more, no less.</p> <p>The combination of C++ implementation, Linux security primitives, and aggressive ephemeral design provides a unique sweet spot: practical privacy without cryptographic complexity, strong isolation without virtualization overhead, and fair access without user management.</p> <p>This is computing as a utility: anonymous, ephemeral, and secure.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Common questions about Sandrun and their answers.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-sandrun","title":"What is Sandrun?","text":"<p>Sandrun is an anonymous, ephemeral, sandboxed code execution service. It allows you to run untrusted code in isolated Linux namespaces without creating accounts or leaving persistent data.</p>"},{"location":"faq/#why-would-i-use-sandrun","title":"Why would I use Sandrun?","text":"<ul> <li>Privacy: No signup, no tracking, all data auto-deletes</li> <li>Security: Hardware-enforced isolation prevents malicious code from escaping</li> <li>Simplicity: Just HTTP POST your code and get results</li> <li>Versatility: Python, JavaScript, Bash, R, Ruby, and more</li> <li>Scalability: Distribute jobs across multiple workers with pool coordinator</li> </ul>"},{"location":"faq/#is-sandrun-free","title":"Is Sandrun free?","text":"<p>Yes! Sandrun is open source under the MIT license. You can run your own instance for free, or use a public instance (subject to rate limits).</p>"},{"location":"faq/#how-does-sandrun-compare-to-docker","title":"How does Sandrun compare to Docker?","text":"Feature Sandrun Docker Startup time &lt;10ms ~1s Memory overhead ~10MB ~100MB Isolation Linux namespaces + seccomp Container with configurable isolation Persistence None (tmpfs only) Optional volumes Network access Blocked by default Configurable Use case Ephemeral code execution Application deployment <p>Sandrun is optimized for short-lived, untrusted code execution, while Docker is better for long-running applications and services.</p>"},{"location":"faq/#security-questions","title":"Security Questions","text":""},{"location":"faq/#is-it-safe-to-run-untrusted-code-in-sandrun","title":"Is it safe to run untrusted code in Sandrun?","text":"<p>Sandrun provides strong isolation using multiple layers:</p> <ol> <li>Linux namespaces (PID, network, mount, IPC, UTS)</li> <li>Seccomp-BPF syscall filtering (~60 safe syscalls only)</li> <li>Capability dropping (no privileged operations)</li> <li>Resource limits (CPU, memory, timeout via cgroups)</li> <li>tmpfs-only storage (no disk access)</li> </ol> <p>However, no system is 100% secure. Sandrun relies on the Linux kernel for isolation. Keep your kernel updated and follow security best practices.</p>"},{"location":"faq/#can-jobs-access-the-network","title":"Can jobs access the network?","text":"<p>No. Jobs run in isolated network namespaces with no external connectivity. This prevents:</p> <ul> <li>Data exfiltration</li> <li>Communication between jobs</li> <li>DDoS attacks from sandboxed code</li> </ul> <p>If your job needs network access, you'll need to modify Sandrun or use a different solution.</p>"},{"location":"faq/#can-jobs-see-other-jobs","title":"Can jobs see other jobs?","text":"<p>No. Each job runs in its own PID namespace and cannot see processes from other jobs or the host system.</p>"},{"location":"faq/#what-happens-to-my-code-after-execution","title":"What happens to my code after execution?","text":"<p>All job data is automatically deleted:</p> <ul> <li>After download: Immediate deletion</li> <li>If failed: 5 minutes retention for debugging</li> <li>If no download: 1 hour maximum retention</li> </ul> <p>Data is stored in tmpfs (RAM only) and never touches disk, so it cannot be recovered after deletion.</p>"},{"location":"faq/#can-the-server-admin-see-my-code","title":"Can the server admin see my code?","text":"<p>The server admin could potentially access job data while jobs are running, since Sandrun runs with root privileges. For maximum privacy:</p> <ul> <li>Run your own Sandrun instance</li> <li>Use encrypted tarballs (decrypt inside the sandbox)</li> <li>Use end-to-end encryption for sensitive workflows</li> </ul>"},{"location":"faq/#usage-questions","title":"Usage Questions","text":""},{"location":"faq/#what-languages-does-sandrun-support","title":"What languages does Sandrun support?","text":"<p>Out of the box:</p> <ul> <li>Python (python3)</li> <li>JavaScript/Node.js (node)</li> <li>Bash (bash)</li> <li>Ruby (ruby)</li> <li>R (Rscript)</li> <li>Perl (perl)</li> <li>PHP (php)</li> </ul> <p>You can add support for other languages by installing them in the environment templates or including static binaries in your job tarball.</p>"},{"location":"faq/#how-do-i-install-dependencies","title":"How do I install dependencies?","text":"<p>Use the <code>requirements</code> field in your manifest:</p> PythonNode.jsRuby <p><pre><code>{\n  \"entrypoint\": \"main.py\",\n  \"requirements\": \"requirements.txt\"\n}\n</code></pre> Runs <code>pip install -r requirements.txt</code> before execution.</p> <p><pre><code>{\n  \"entrypoint\": \"main.js\",\n  \"requirements\": \"package.json\"\n}\n</code></pre> Runs <code>npm install</code> before execution.</p> <p><pre><code>{\n  \"entrypoint\": \"main.rb\",\n  \"requirements\": \"Gemfile\"\n}\n</code></pre> Runs <code>bundle install</code> before execution.</p>"},{"location":"faq/#what-are-environment-templates","title":"What are environment templates?","text":"<p>Pre-built environments with common packages:</p> <ul> <li>default: Minimal system tools</li> <li>ml-basic: NumPy, SciPy, pandas, scikit-learn</li> <li>vision: OpenCV, Pillow, scikit-image</li> <li>nlp: NLTK, spaCy, transformers</li> <li>data-science: Jupyter, matplotlib, seaborn</li> <li>scientific: SymPy, NetworkX, statsmodels</li> </ul> <p>Use them in your manifest: <pre><code>{\n  \"entrypoint\": \"train.py\",\n  \"environment\": \"ml-basic\"\n}\n</code></pre></p>"},{"location":"faq/#how-do-i-download-output-files","title":"How do I download output files?","text":"<ol> <li> <p>Specify outputs in manifest: <pre><code>{\n  \"outputs\": [\"results/\", \"*.png\", \"model.pkl\"]\n}\n</code></pre></p> </li> <li> <p>List available outputs: <pre><code>curl http://localhost:8443/outputs/job-abc123\n</code></pre></p> </li> <li> <p>Download specific file: <pre><code>curl http://localhost:8443/download/job-abc123/results/output.png -o output.png\n</code></pre></p> </li> </ol>"},{"location":"faq/#whats-the-maximum-job-size","title":"What's the maximum job size?","text":"<ul> <li>Tarball upload: 100MB (configurable)</li> <li>Memory per job: 512MB (configurable)</li> <li>Timeout: 5 minutes (configurable)</li> <li>CPU quota: 10 seconds per minute per IP</li> </ul>"},{"location":"faq/#can-i-run-long-running-jobs","title":"Can I run long-running jobs?","text":"<p>By default, jobs timeout after 5 minutes. For longer jobs:</p> <ol> <li> <p>Increase timeout in manifest: <pre><code>{\n  \"timeout\": 3600  // 1 hour\n}\n</code></pre></p> </li> <li> <p>Note: Long jobs consume more CPU quota, which may prevent you from submitting additional jobs.</p> </li> </ol>"},{"location":"faq/#how-do-i-check-job-status","title":"How do I check job status?","text":"<pre><code># Get status\ncurl http://localhost:8443/status/job-abc123\n\n# Poll until complete\nwhile true; do\n  STATUS=$(curl -s http://localhost:8443/status/job-abc123 | jq -r '.status')\n  echo \"Status: $STATUS\"\n  [ \"$STATUS\" = \"completed\" ] || [ \"$STATUS\" = \"failed\" ] &amp;&amp; break\n  sleep 2\ndone\n</code></pre> <p>Or use WebSocket streaming: <pre><code>const ws = new WebSocket('ws://localhost:8443/logs/job-abc123/stream');\nws.onmessage = (event) =&gt; console.log(event.data);\n</code></pre></p>"},{"location":"faq/#rate-limiting-questions","title":"Rate Limiting Questions","text":""},{"location":"faq/#what-are-the-rate-limits","title":"What are the rate limits?","text":"<p>Default limits per IP address:</p> <ul> <li>10 CPU-seconds per minute</li> <li>2 concurrent jobs maximum</li> <li>512MB RAM per job</li> <li>5 minute timeout per job</li> </ul>"},{"location":"faq/#how-is-cpu-quota-calculated","title":"How is CPU quota calculated?","text":"<p>CPU quota measures actual CPU time, not wall-clock time:</p> <ul> <li>A 2-second job using 1 CPU core = 2 CPU-seconds</li> <li>A 1-second job using 4 CPU cores = 4 CPU-seconds</li> </ul>"},{"location":"faq/#what-happens-if-i-exceed-quota","title":"What happens if I exceed quota?","text":"<p>You'll receive a 429 error: <pre><code>{\n  \"error\": \"Rate limit exceeded\",\n  \"reason\": \"CPU quota exhausted (10.2/10.0 seconds used)\",\n  \"retry_after\": 45\n}\n</code></pre></p> <p>Wait for the <code>retry_after</code> seconds, or for 1 hour of inactivity to reset quota.</p>"},{"location":"faq/#can-i-increase-my-rate-limits","title":"Can I increase my rate limits?","text":"<p>If running your own instance, edit the configuration in the source code. If using a public instance, you'll need to follow their policies (or run your own!).</p>"},{"location":"faq/#pool-distribution-questions","title":"Pool &amp; Distribution Questions","text":""},{"location":"faq/#what-is-the-pool-coordinator","title":"What is the pool coordinator?","text":"<p>The pool coordinator distributes jobs across multiple Sandrun workers for horizontal scaling. It provides:</p> <ul> <li>Health checking of workers</li> <li>Load balancing across available workers</li> <li>Centralized job submission</li> <li>Result proxying</li> </ul> <p>Learn more \u2192</p>"},{"location":"faq/#how-do-i-set-up-a-pool","title":"How do I set up a pool?","text":"<ol> <li>Start multiple Sandrun workers with worker keys</li> <li>Create <code>workers.json</code> with worker public keys</li> <li>Run pool coordinator with worker allowlist</li> <li>Submit jobs to coordinator instead of individual workers</li> </ol> <p>Detailed setup guide \u2192</p>"},{"location":"faq/#whats-the-difference-between-trusted-and-trustless-pools","title":"What's the difference between trusted and trustless pools?","text":"Feature Trusted Pool Trustless Pool Worker authorization Allowlist (public keys) Open (anyone) Result verification None (trust workers) Consensus + verification Economic model None Stake/slashing Complexity Simple (~200 lines) Complex Use case Private cluster Public compute <p>Most users should use the trusted pool for private deployments.</p>"},{"location":"faq/#integration-questions","title":"Integration Questions","text":""},{"location":"faq/#can-i-use-sandrun-with-claude","title":"Can I use Sandrun with Claude?","text":"<p>Yes! The MCP (Model Context Protocol) server integration allows Claude Desktop to execute code via Sandrun:</p> <ol> <li>Install MCP server: <code>pip install -e integrations/mcp-server</code></li> <li>Add to Claude Desktop config</li> <li>Ask Claude to execute code</li> </ol> <p>MCP integration guide \u2192</p>"},{"location":"faq/#how-do-i-integrate-sandrun-into-my-app","title":"How do I integrate Sandrun into my app?","text":"<p>Use the REST API directly:</p> <pre><code>import requests\n\n# Submit job\nresponse = requests.post('http://localhost:8443/submit',\n    files={'files': open('job.tar.gz', 'rb')},\n    data={'manifest': '{\"entrypoint\":\"main.py\"}'})\n\njob_id = response.json()['job_id']\n\n# Get results\nstatus = requests.get(f'http://localhost:8443/status/{job_id}').json()\n</code></pre> <p>See API Reference for full documentation.</p>"},{"location":"faq/#can-i-use-sandrun-in-cicd","title":"Can I use Sandrun in CI/CD?","text":"<p>Yes! Sandrun is great for isolated test execution:</p> <pre><code># .github/workflows/test.yml\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Run tests in Sandrun\n        run: |\n          tar czf tests.tar.gz tests/\n          curl -X POST http://sandrun.example.com:8443/submit \\\n            -F \"files=@tests.tar.gz\" \\\n            -F 'manifest={\"entrypoint\":\"run_tests.sh\"}'\n</code></pre>"},{"location":"faq/#troubleshooting-questions","title":"Troubleshooting Questions","text":""},{"location":"faq/#why-is-my-job-stuck-in-queued-status","title":"Why is my job stuck in \"queued\" status?","text":"<p>Possible causes:</p> <ol> <li>No available workers (if using pool)</li> <li>Rate limit reached (2 concurrent jobs per IP)</li> <li>Server overloaded (check <code>/stats</code> endpoint)</li> </ol>"},{"location":"faq/#why-did-my-job-fail","title":"Why did my job fail?","text":"<p>Check logs for errors: <pre><code>curl http://localhost:8443/logs/job-abc123\n</code></pre></p> <p>Common causes:</p> <ul> <li>Missing files in tarball</li> <li>Syntax errors in code</li> <li>Missing dependencies</li> <li>Exceeded memory limit</li> <li>Timeout (job took too long)</li> </ul>"},{"location":"faq/#how-do-i-report-bugs","title":"How do I report bugs?","text":"<ol> <li>Check GitHub Issues for existing reports</li> <li>Create new issue with:</li> <li>Sandrun version (<code>./build/sandrun --version</code>)</li> <li>Operating system and kernel version</li> <li>Steps to reproduce</li> <li>Error messages and logs</li> </ol>"},{"location":"faq/#where-can-i-get-help","title":"Where can I get help?","text":"<ul> <li>Documentation: This site!</li> <li>GitHub Discussions: Ask questions, share use cases</li> <li>GitHub Issues: Report bugs and request features</li> <li>Source Code: Read the code in <code>src/</code></li> </ul>"},{"location":"faq/#performance-questions","title":"Performance Questions","text":""},{"location":"faq/#how-fast-is-sandrun","title":"How fast is Sandrun?","text":"<ul> <li>Job startup: &lt;10ms</li> <li>API latency: &lt;50ms</li> <li>Throughput: 100+ jobs/second (on modern hardware)</li> <li>Overhead: &lt;1% CPU for orchestration</li> </ul>"},{"location":"faq/#can-sandrun-handle-gpu-workloads","title":"Can Sandrun handle GPU workloads?","text":"<p>Yes! Use the <code>gpu</code> field in your manifest:</p> <pre><code>{\n  \"entrypoint\": \"train.py\",\n  \"gpu\": {\n    \"required\": true,\n    \"min_vram_gb\": 8,\n    \"cuda_version\": \"11.8\"\n  }\n}\n</code></pre> <p>Note: GPU support requires proper NVIDIA drivers and configuration on the host.</p>"},{"location":"faq/#how-does-sandrun-scale","title":"How does Sandrun scale?","text":"<ul> <li>Vertical: Single instance can handle 100+ jobs/second</li> <li>Horizontal: Use pool coordinator to distribute across multiple workers</li> <li>Geographic: Deploy pools in different regions</li> </ul>"},{"location":"faq/#development-questions","title":"Development Questions","text":""},{"location":"faq/#how-do-i-build-sandrun-from-source","title":"How do I build Sandrun from source?","text":"<pre><code>git clone https://github.com/yourusername/sandrun.git\ncd sandrun\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build -j$(nproc)\n</code></pre> <p>Full build guide \u2192</p>"},{"location":"faq/#how-do-i-contribute","title":"How do I contribute?","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Write tests for your changes</li> <li>Submit a pull request</li> </ol> <p>Contributing guidelines \u2192</p>"},{"location":"faq/#where-is-the-code","title":"Where is the code?","text":"<ul> <li>C++ Backend: <code>src/</code></li> <li>Integrations: <code>integrations/</code></li> <li>Tests: <code>tests/</code></li> <li>Documentation: <code>docs/</code></li> </ul> <p>Have more questions? Open a discussion on GitHub \u2192</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will walk you through installing Sandrun, running your first job, and understanding the core workflow.</p> <p>Estimated Time</p> <p>5-10 minutes to install and run your first job</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before installing Sandrun, ensure your system meets these requirements:</p>"},{"location":"getting-started/#system-requirements","title":"System Requirements","text":"Requirement Specification Operating System Linux (Ubuntu 20.04+, Debian 11+, or equivalent) Kernel Version 4.6+ (for namespace support) RAM 2GB minimum (4GB+ recommended) Disk Space 500MB for build artifacts Root Access Required for namespace creation"},{"location":"getting-started/#check-your-system","title":"Check Your System","text":"<pre><code># Verify kernel version (should be 4.6+)\nuname -r\n\n# Check if namespaces are supported\nls /proc/self/ns/\n\n# Verify seccomp support\ncat /proc/sys/kernel/seccomp  # Should output: 2\n</code></pre> <p>Root Permissions Required</p> <p>Sandrun requires root privileges to create Linux namespaces. You'll need to run it with <code>sudo</code> or grant the CAP_SYS_ADMIN capability.</p>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#1-install-dependencies","title":"1. Install Dependencies","text":"Ubuntu/DebianFedora/RHELArch Linux <pre><code>sudo apt-get update\nsudo apt-get install -y \\\n  build-essential \\\n  cmake \\\n  libseccomp-dev \\\n  libcap-dev \\\n  libssl-dev \\\n  pkg-config \\\n  git\n</code></pre> <pre><code>sudo dnf install -y \\\n  gcc-c++ \\\n  cmake \\\n  libseccomp-devel \\\n  libcap-devel \\\n  openssl-devel \\\n  pkgconfig \\\n  git\n</code></pre> <pre><code>sudo pacman -S \\\n  base-devel \\\n  cmake \\\n  libseccomp \\\n  libcap \\\n  openssl \\\n  pkgconf \\\n  git\n</code></pre>"},{"location":"getting-started/#2-clone-and-build","title":"2. Clone and Build","text":"<pre><code># Clone repository\ngit clone https://github.com/yourusername/sandrun.git\ncd sandrun\n\n# Configure build\ncmake -B build -DCMAKE_BUILD_TYPE=Release\n\n# Build (use -j for parallel compilation)\ncmake --build build -j$(nproc)\n\n# Verify build\n./build/sandrun --help\n</code></pre> <p>Build Output</p> <p>If successful, you should see: <pre><code>Usage: sandrun [options]\nOptions:\n  --port PORT          Server port (default: 8443)\n  --worker-key FILE    Worker private key for signing\n  --generate-key FILE  Generate new worker keypair\n  --help              Show this help message\n</code></pre></p>"},{"location":"getting-started/#3-run-server","title":"3. Run Server","text":"<pre><code># Start server (requires sudo for namespace creation)\nsudo ./build/sandrun --port 8443\n</code></pre> <p>Expected Output: <pre><code>[INFO] Sandrun v1.0.0 starting...\n[INFO] Initializing sandbox environment\n[INFO] Loading environment templates\n[INFO] Server listening on http://0.0.0.0:8443\n[INFO] Press Ctrl+C to stop\n</code></pre></p> <p>Running Without Sudo</p> <p>For production deployments, you can grant specific capabilities instead of full root: <pre><code>sudo setcap cap_sys_admin,cap_sys_chroot,cap_setuid,cap_setgid+ep ./build/sandrun\n./build/sandrun --port 8443  # No sudo needed\n</code></pre></p>"},{"location":"getting-started/#your-first-job","title":"Your First Job","text":""},{"location":"getting-started/#simple-python-script","title":"Simple Python Script","text":"<pre><code># Create script\ncat &gt; hello.py &lt;&lt;'EOF'\nprint(\"Hello from Sandrun!\")\nimport sys\nprint(f\"Python version: {sys.version}\")\nEOF\n\n# Create manifest\ncat &gt; job.json &lt;&lt;'EOF'\n{\n  \"entrypoint\": \"hello.py\",\n  \"interpreter\": \"python3\"\n}\nEOF\n\n# Package files\ntar czf job.tar.gz hello.py\n\n# Submit job\ncurl -X POST http://localhost:8443/submit \\\n  -F \"files=@job.tar.gz\" \\\n  -F \"manifest=$(cat job.json)\"\n\n# Response:\n# {\n#   \"job_id\": \"job-abc123def456\",\n#   \"status\": \"queued\"\n# }\n</code></pre>"},{"location":"getting-started/#check-job-status","title":"Check Job Status","text":"<pre><code># Get status\ncurl http://localhost:8443/status/job-abc123def456\n\n# Response:\n# {\n#   \"job_id\": \"job-abc123def456\",\n#   \"status\": \"completed\",\n#   \"execution_metadata\": {\n#     \"cpu_seconds\": 0.05,\n#     \"memory_peak_bytes\": 12582912,\n#     \"exit_code\": 0\n#   },\n#   \"output_files\": {\n#     ...\n#   }\n# }\n</code></pre>"},{"location":"getting-started/#get-logs","title":"Get Logs","text":"<pre><code># Get stdout\ncurl http://localhost:8443/logs/job-abc123def456\n\n# Response:\n# Hello from Sandrun!\n# Python version: 3.10.12 (main, ...)\n</code></pre>"},{"location":"getting-started/#multi-file-projects","title":"Multi-File Projects","text":""},{"location":"getting-started/#upload-entire-directory","title":"Upload Entire Directory","text":"<pre><code># Create project\nmkdir my-project\ncd my-project\n\ncat &gt; main.py &lt;&lt;'EOF'\nfrom utils import greet\n\ngreet(\"World\")\nEOF\n\ncat &gt; utils.py &lt;&lt;'EOF'\ndef greet(name):\n    print(f\"Hello, {name}!\")\nEOF\n\ncat &gt; job.json &lt;&lt;'EOF'\n{\n  \"entrypoint\": \"main.py\",\n  \"interpreter\": \"python3\",\n  \"outputs\": [\"*.txt\", \"results/\"]\n}\nEOF\n\n# Package and submit\ntar czf ../my-project.tar.gz .\ncd ..\ncurl -X POST http://localhost:8443/submit \\\n  -F \"files=@my-project.tar.gz\" \\\n  -F \"manifest=$(cat my-project/job.json)\"\n</code></pre>"},{"location":"getting-started/#using-environments","title":"Using Environments","text":"<p>Sandrun supports pre-built environments with common packages:</p> <pre><code>cat &gt; job.json &lt;&lt;'EOF'\n{\n  \"entrypoint\": \"ml_script.py\",\n  \"interpreter\": \"python3\",\n  \"environment\": \"ml-basic\"\n}\nEOF\n</code></pre> <p>Available environments:</p> <ul> <li><code>ml-basic</code> - NumPy, SciPy, pandas</li> <li><code>vision</code> - OpenCV, Pillow, scikit-image</li> <li><code>nlp</code> - NLTK, spaCy, transformers</li> <li><code>data-science</code> - Jupyter, matplotlib, seaborn</li> <li><code>scientific</code> - SymPy, NetworkX, statsmodels</li> </ul> <p>List available environments:</p> <pre><code>curl http://localhost:8443/environments\n</code></pre>"},{"location":"getting-started/#worker-identity-optional","title":"Worker Identity (Optional)","text":"<p>Generate a worker identity for signed results:</p> <pre><code># Generate key\nsudo ./build/sandrun --generate-key /etc/sandrun/worker.pem\n\n# Output:\n# \u2705 Saved worker key to: /etc/sandrun/worker.pem\n#    Worker ID: &lt;base64-encoded-public-key&gt;\n\n# Start with identity\nsudo ./build/sandrun --port 8443 --worker-key /etc/sandrun/worker.pem\n</code></pre> <p>Jobs executed by this worker will include:</p> <pre><code>{\n  \"worker_metadata\": {\n    \"worker_id\": \"base64-encoded-public-key\",\n    \"signature\": \"base64-encoded-signature\"\n  }\n}\n</code></pre>"},{"location":"getting-started/#rate-limits","title":"Rate Limits","text":"<p>Sandrun enforces IP-based rate limits:</p> <ul> <li>10 CPU-seconds per minute per IP</li> <li>512MB RAM per job</li> <li>5 minute timeout per job</li> <li>2 concurrent jobs per IP</li> </ul> <p>Check your quota:</p> <pre><code>curl http://localhost:8443/stats\n\n# Response:\n# {\n#   \"your_quota\": {\n#     \"used\": 2.5,\n#     \"limit\": 10.0,\n#     \"available\": 7.5,\n#     \"active_jobs\": 1,\n#     \"can_submit\": true\n#   },\n#   \"system\": {\n#     \"queue_length\": 3,\n#     \"active_jobs\": 5\n#   }\n# }\n</code></pre>"},{"location":"getting-started/#understanding-rate-limits","title":"Understanding Rate Limits","text":"<p>Sandrun uses IP-based rate limiting to ensure fair resource sharing:</p>"},{"location":"getting-started/#default-limits","title":"Default Limits","text":"Limit Type Value Window CPU Quota 10 CPU-seconds Per minute Concurrent Jobs 2 jobs At a time Memory per Job 512MB Per job Timeout 5 minutes Per job"},{"location":"getting-started/#check-your-quota","title":"Check Your Quota","text":"<pre><code>curl http://localhost:8443/stats\n</code></pre> <p>Response: <pre><code>{\n  \"your_quota\": {\n    \"used\": 2.5,\n    \"limit\": 10.0,\n    \"available\": 7.5,\n    \"active_jobs\": 1,\n    \"can_submit\": true\n  },\n  \"system\": {\n    \"queue_length\": 3,\n    \"active_jobs\": 5\n  }\n}\n</code></pre></p> <p>Quota Management</p> <ul> <li>Quota resets after 1 hour of inactivity</li> <li>CPU time is measured in actual CPU seconds, not wall-clock time</li> <li>Use different IP addresses for separate quotas (if needed for testing)</li> </ul>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/#permission-denied","title":"Permission Denied","text":"<p>Symptom: <pre><code>Error: Permission denied creating namespace\n</code></pre></p> <p>Solutions:</p> Use sudoGrant capabilitiesCheck user namespaces <pre><code>sudo ./build/sandrun --port 8443\n</code></pre> <pre><code>sudo setcap cap_sys_admin,cap_sys_chroot,cap_setuid,cap_setgid+ep ./build/sandrun\n./build/sandrun --port 8443\n</code></pre> <pre><code># Some systems disable user namespaces for security\ncat /proc/sys/kernel/unprivileged_userns_clone\n# Should output: 1 (enabled)\n\n# If disabled, enable it:\nsudo sysctl -w kernel.unprivileged_userns_clone=1\n</code></pre>"},{"location":"getting-started/#port-already-in-use","title":"Port Already in Use","text":"<p>Symptom: <pre><code>Error: Failed to bind to port 8443: Address already in use\n</code></pre></p> <p>Solutions:</p> <pre><code># Option 1: Use a different port\nsudo ./build/sandrun --port 9000\n\n# Option 2: Find and kill the process using the port\nsudo lsof -i :8443\nsudo kill &lt;PID&gt;\n\n# Option 3: Let the OS assign a port\nsudo ./build/sandrun --port 0  # Uses random available port\n</code></pre>"},{"location":"getting-started/#build-failures","title":"Build Failures","text":"<p>Symptom: <pre><code>CMake Error: Could not find libseccomp\n</code></pre></p> <p>Solution: <pre><code># Ensure all dependencies are installed\nsudo apt-get install -y libseccomp-dev libcap-dev libssl-dev\n\n# Clean and rebuild\nrm -rf build\ncmake -B build\ncmake --build build\n</code></pre></p>"},{"location":"getting-started/#job-failed-to-execute","title":"Job Failed to Execute","text":"<p>Symptom: Job status shows <code>\"status\": \"failed\"</code> with non-zero exit code.</p> <p>Debugging Steps:</p> <ol> <li> <p>Check logs for errors: <pre><code>curl http://localhost:8443/logs/job-abc123\n</code></pre></p> </li> <li> <p>Verify manifest syntax: <pre><code>echo '{\"entrypoint\":\"main.py\",\"interpreter\":\"python3\"}' | jq .\n</code></pre></p> </li> <li> <p>Check file permissions: <pre><code># Ensure entrypoint is included in tarball\ntar -tzf job.tar.gz\n</code></pre></p> </li> <li> <p>Test locally first: <pre><code>python3 main.py  # Test before submitting\n</code></pre></p> </li> </ol>"},{"location":"getting-started/#rate-limit-exceeded","title":"Rate Limit Exceeded","text":"<p>Symptom: <pre><code>{\n  \"error\": \"Rate limit exceeded\",\n  \"reason\": \"CPU quota exhausted (10.2/10.0 seconds used)\",\n  \"retry_after\": 45\n}\n</code></pre></p> <p>Solutions:</p> <ul> <li>Wait for quota refresh (shown in <code>retry_after</code> field)</li> <li>Optimize your code to use less CPU time</li> <li>Split jobs into smaller chunks</li> <li>Use different IP (for testing only)</li> </ul>"},{"location":"getting-started/#cannot-access-server","title":"Cannot Access Server","text":"<p>Symptom: <pre><code>curl: (7) Failed to connect to localhost port 8443: Connection refused\n</code></pre></p> <p>Checklist:</p> <ol> <li> <p>Verify server is running: <pre><code>ps aux | grep sandrun\n</code></pre></p> </li> <li> <p>Check if port is listening: <pre><code>sudo netstat -tlnp | grep 8443\n</code></pre></p> </li> <li> <p>Check firewall rules: <pre><code>sudo ufw status\nsudo iptables -L -n | grep 8443\n</code></pre></p> </li> <li> <p>Verify server logs: <pre><code># If running in terminal, check stdout\n# Or check system logs if running as service\njournalctl -u sandrun -f\n</code></pre></p> </li> </ol>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference - Complete API documentation</li> <li>Job Manifest - Advanced job configuration</li> <li>Integrations - Pool coordinator, MCP server</li> <li>Architecture - Understand the internals</li> </ul>"},{"location":"job-manifest/","title":"Job Manifest Specification","text":""},{"location":"job-manifest/#overview","title":"Overview","text":"<p>Each job submitted to Sandrun can include a manifest file (<code>job.json</code>) that specifies execution parameters. This allows for reproducible, queue-friendly batch processing.</p>"},{"location":"job-manifest/#manifest-format","title":"Manifest Format","text":"<pre><code>{\n  \"entrypoint\": \"main.py\",\n  \"interpreter\": \"python3\", \n  \"args\": [\"--input\", \"data.csv\"],\n  \"env\": {\n    \"PYTHONPATH\": \"./lib\"\n  },\n  \"outputs\": [\n    \"results/\",\n    \"*.png\",\n    \"logs/*.log\"\n  ],\n  \"requirements\": \"requirements.txt\",\n  \"timeout\": 300,\n  \"memory_mb\": 512,\n  \"cpu_seconds\": 10\n}\n</code></pre>"},{"location":"job-manifest/#fields","title":"Fields","text":""},{"location":"job-manifest/#entrypoint-required","title":"<code>entrypoint</code> (required)","text":"<ul> <li>Type: string</li> <li>Description: The script or binary to execute</li> <li>Examples: <code>\"main.py\"</code>, <code>\"run.sh\"</code>, <code>\"analyze.R\"</code></li> </ul>"},{"location":"job-manifest/#interpreter-optional","title":"<code>interpreter</code> (optional)","text":"<ul> <li>Type: string  </li> <li>Default: Auto-detected from file extension</li> <li>Options: <code>\"python3\"</code>, <code>\"node\"</code>, <code>\"bash\"</code>, <code>\"ruby\"</code>, <code>\"Rscript\"</code></li> <li>Description: The interpreter to use for the entrypoint</li> </ul>"},{"location":"job-manifest/#args-optional","title":"<code>args</code> (optional)","text":"<ul> <li>Type: array of strings</li> <li>Default: <code>[]</code></li> <li>Description: Command-line arguments to pass to the entrypoint</li> <li>Example: <code>[\"--input\", \"data.csv\", \"--verbose\"]</code></li> </ul>"},{"location":"job-manifest/#env-optional","title":"<code>env</code> (optional)","text":"<ul> <li>Type: object</li> <li>Default: <code>{}</code></li> <li>Description: Environment variables to set</li> <li>Note: Cannot override system security variables</li> </ul>"},{"location":"job-manifest/#outputs-optional","title":"<code>outputs</code> (optional)","text":"<ul> <li>Type: array of strings (glob patterns)</li> <li>Default: <code>[\"*\"]</code> (everything)</li> <li>Description: Files/directories to include in output download</li> <li>Examples:</li> <li><code>\"results/\"</code> - Include entire results directory</li> <li><code>\"*.png\"</code> - All PNG files</li> <li><code>\"output.json\"</code> - Specific file</li> <li><code>\"logs/*.log\"</code> - All log files in logs directory</li> </ul>"},{"location":"job-manifest/#requirements-optional","title":"<code>requirements</code> (optional)","text":"<ul> <li>Type: string</li> <li>Description: Dependencies file to install before execution</li> <li>Supported:</li> <li>Python: <code>\"requirements.txt\"</code> \u2192 runs <code>pip install -r requirements.txt</code></li> <li>Node: <code>\"package.json\"</code> \u2192 runs <code>npm install</code></li> <li>Ruby: <code>\"Gemfile\"</code> \u2192 runs <code>bundle install</code></li> </ul>"},{"location":"job-manifest/#timeout-optional","title":"<code>timeout</code> (optional)","text":"<ul> <li>Type: integer (seconds)</li> <li>Default: 300 (5 minutes)</li> <li>Maximum: 3600 (1 hour)</li> <li>Description: Maximum execution time</li> </ul>"},{"location":"job-manifest/#memory_mb-optional","title":"<code>memory_mb</code> (optional)","text":"<ul> <li>Type: integer</li> <li>Default: 512</li> <li>Maximum: 2048</li> <li>Description: Memory limit in megabytes</li> </ul>"},{"location":"job-manifest/#cpu_seconds-optional","title":"<code>cpu_seconds</code> (optional)","text":"<ul> <li>Type: integer</li> <li>Default: 10</li> <li>Maximum: 60</li> <li>Description: CPU seconds per minute quota</li> </ul>"},{"location":"job-manifest/#gpu-optional","title":"<code>gpu</code> (optional)","text":"<ul> <li>Type: object</li> <li>Description: GPU requirements for ML/compute workloads</li> <li>Fields:</li> <li><code>required</code> (boolean): Whether GPU is required</li> <li><code>device_id</code> (integer): Specific GPU device (default: 0)</li> <li><code>min_vram_gb</code> (integer): Minimum VRAM required in GB</li> <li><code>cuda_version</code> (string): Minimum CUDA version (e.g., \"11.8\")</li> <li><code>compute_capability</code> (string): Minimum compute capability (e.g., \"7.0\")</li> <li>Example:   <pre><code>{\n  \"required\": true,\n  \"min_vram_gb\": 8,\n  \"cuda_version\": \"11.8\",\n  \"compute_capability\": \"7.0\"\n}\n</code></pre></li> </ul>"},{"location":"job-manifest/#execution-flow","title":"Execution Flow","text":"<ol> <li>Upload: User uploads directory with code and <code>job.json</code></li> <li>Queue: Job enters queue with manifest metadata</li> <li>Prepare: When job starts:</li> <li>Extract files to sandbox</li> <li>Install dependencies if specified</li> <li>Set environment variables</li> <li>Execute: Run entrypoint with args</li> <li>Capture: </li> <li>stdout \u2192 <code>stdout.log</code></li> <li>stderr \u2192 <code>stderr.log</code></li> <li>Both streamed to API for live viewing</li> <li>Package: Create output archive with files matching <code>outputs</code> patterns</li> <li>Cleanup: Delete all job data after download or timeout</li> </ol>"},{"location":"job-manifest/#examples","title":"Examples","text":""},{"location":"job-manifest/#python-data-analysis","title":"Python Data Analysis","text":"<pre><code>{\n  \"entrypoint\": \"analyze.py\",\n  \"args\": [\"--dataset\", \"sales.csv\"],\n  \"outputs\": [\"figures/\", \"report.pdf\"],\n  \"requirements\": \"requirements.txt\",\n  \"memory_mb\": 1024\n}\n</code></pre>"},{"location":"job-manifest/#nodejs-build-job","title":"Node.js Build Job","text":"<pre><code>{\n  \"entrypoint\": \"build.js\",\n  \"interpreter\": \"node\",\n  \"env\": {\n    \"NODE_ENV\": \"production\"\n  },\n  \"outputs\": [\"dist/\"],\n  \"requirements\": \"package.json\"\n}\n</code></pre>"},{"location":"job-manifest/#shell-script-pipeline","title":"Shell Script Pipeline","text":"<pre><code>{\n  \"entrypoint\": \"pipeline.sh\",\n  \"interpreter\": \"bash\",\n  \"outputs\": [\"processed/*.csv\", \"summary.txt\"],\n  \"timeout\": 600\n}\n</code></pre>"},{"location":"job-manifest/#r-statistical-analysis","title":"R Statistical Analysis","text":"<pre><code>{\n  \"entrypoint\": \"model.R\",\n  \"interpreter\": \"Rscript\",\n  \"args\": [\"--confidence\", \"0.95\"],\n  \"outputs\": [\"plots/*.png\", \"results.rds\"]\n}\n</code></pre>"},{"location":"job-manifest/#ml-training-with-gpu","title":"ML Training with GPU","text":"<pre><code>{\n  \"entrypoint\": \"train.py\",\n  \"args\": [\"--epochs\", \"10\", \"--batch-size\", \"32\"],\n  \"gpu\": {\n    \"required\": true,\n    \"min_vram_gb\": 8,\n    \"cuda_version\": \"11.8\"\n  },\n  \"outputs\": [\"checkpoints/\", \"metrics.json\"],\n  \"requirements\": \"requirements.txt\",\n  \"timeout\": 1800,\n  \"memory_mb\": 2048\n}\n</code></pre>"},{"location":"job-manifest/#stable-diffusion-inference","title":"Stable Diffusion Inference","text":"<pre><code>{\n  \"entrypoint\": \"generate.py\",\n  \"args\": [\"--prompt\", \"a beautiful sunset\", \"--steps\", \"50\"],\n  \"gpu\": {\n    \"required\": true,\n    \"min_vram_gb\": 6,\n    \"compute_capability\": \"7.0\"\n  },\n  \"outputs\": [\"images/*.png\"],\n  \"timeout\": 600\n}\n</code></pre>"},{"location":"job-manifest/#privacy-considerations","title":"Privacy Considerations","text":"<ul> <li>Manifest is deleted immediately after job parsing</li> <li>No manifest contents are logged (only metrics)</li> <li>Output patterns are applied before download (unmatched files never leave sandbox)</li> <li>All job data auto-deleted after:</li> <li>Successful download (immediate)</li> <li>Job failure (5 minutes)</li> <li>No download (1 hour)</li> </ul>"},{"location":"job-manifest/#api-endpoints","title":"API Endpoints","text":""},{"location":"job-manifest/#submit-job","title":"Submit Job","text":"<pre><code>POST /submit\nContent-Type: multipart/form-data\n\nFiles: [project files]\nManifest: job.json (optional, can be in files or separate field)\n</code></pre>"},{"location":"job-manifest/#get-status","title":"Get Status","text":"<pre><code>GET /status/{job_id}\n\nReturns:\n{\n  \"status\": \"queued|running|completed|failed\",\n  \"queue_position\": 3,\n  \"metrics\": {\n    \"cpu_seconds\": 2.34,\n    \"memory_mb\": 128,\n    \"runtime\": 45\n  }\n}\n</code></pre>"},{"location":"job-manifest/#stream-logs","title":"Stream Logs","text":"<pre><code>GET /logs/{job_id}\n\nReturns:\n{\n  \"stdout\": \"...\",\n  \"stderr\": \"...\"\n}\n</code></pre>"},{"location":"job-manifest/#list-outputs","title":"List Outputs","text":"<pre><code>GET /outputs/{job_id}\n\nReturns:\n{\n  \"files\": [\"results/analysis.csv\", \"plot.png\"]\n}\n</code></pre>"},{"location":"job-manifest/#download-outputs","title":"Download Outputs","text":"<pre><code>GET /download/{job_id}          # All outputs as tar.gz\nGET /download/{job_id}/{file}   # Specific file\n</code></pre>"},{"location":"security/","title":"Security Best Practices","text":"<p>Comprehensive security guide for deploying and using Sandrun safely.</p>"},{"location":"security/#overview","title":"Overview","text":"<p>Sandrun is designed for untrusted code execution with strong isolation. However, security is a shared responsibility between the Sandrun software and the deployment environment.</p> <p>Important Security Notice</p> <p>While Sandrun provides robust isolation, it relies on the Linux kernel. Always keep your kernel and system updated with the latest security patches.</p>"},{"location":"security/#isolation-layers","title":"Isolation Layers","text":"<p>Sandrun uses defense-in-depth with multiple isolation layers:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Application Code (Untrusted)      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Seccomp-BPF (~60 safe syscalls)   \u2502 \u2190 Syscall filtering\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Linux Namespaces                   \u2502 \u2190 Process/network/mount isolation\n\u2502  - PID, Network, Mount, IPC, UTS   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Capability Dropping                \u2502 \u2190 No privileged operations\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Cgroups                           \u2502 \u2190 Resource limits\n\u2502  - CPU quota, Memory limit         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  tmpfs (RAM-only storage)          \u2502 \u2190 No persistent storage\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Linux Kernel                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Hardware                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"security/#1-linux-namespaces","title":"1. Linux Namespaces","text":"<p>Each job runs in isolated namespaces:</p> <ul> <li>PID namespace: Job cannot see other processes</li> <li>Network namespace: No network access (airgapped)</li> <li>Mount namespace: Private filesystem view</li> <li>IPC namespace: No inter-process communication</li> <li>UTS namespace: Isolated hostname</li> </ul>"},{"location":"security/#2-seccomp-bpf-syscall-filtering","title":"2. Seccomp-BPF Syscall Filtering","text":"<p>Sandrun uses a whitelist of ~60 safe syscalls including:</p> <pre><code>// Allowed syscalls (examples)\nread, write, open, close, stat, fstat\nmmap, munmap, brk\nexit, exit_group\ngetpid, getuid, getgid\nfutex, nanosleep\n</code></pre> <p>Blocked syscalls (dangerous operations):</p> <pre><code>// Blocked syscalls\nsocket, connect, bind, listen  // Network access\nptrace, perf_event_open        // Process debugging\nreboot, kexec_load             // System control\nmodule_init, module_finit      // Kernel modules\n</code></pre>"},{"location":"security/#3-capability-dropping","title":"3. Capability Dropping","text":"<p>All Linux capabilities are dropped before execution:</p> <pre><code>CAP_SYS_ADMIN    // System administration\nCAP_NET_ADMIN    // Network administration\nCAP_SYS_MODULE   // Load kernel modules\n// ... and 35+ more capabilities\n</code></pre>"},{"location":"security/#4-resource-limits","title":"4. Resource Limits","text":"<p>Cgroups enforce hard limits:</p> <ul> <li>CPU: 10 seconds per minute per IP</li> <li>Memory: 512MB per job</li> <li>Timeout: 5 minutes maximum</li> <li>Processes: 100 processes per job</li> </ul>"},{"location":"security/#5-tmpfs-only-storage","title":"5. tmpfs-only Storage","text":"<p>All job data stored in RAM (tmpfs):</p> <ul> <li>No disk writes: Data never touches persistent storage</li> <li>Automatic cleanup: Memory released on job completion</li> <li>No swap: Memory pages locked to prevent disk swap</li> </ul>"},{"location":"security/#threat-model","title":"Threat Model","text":""},{"location":"security/#what-sandrun-protects-against","title":"What Sandrun Protects Against","text":""},{"location":"security/#filesystem-escape","title":"\u2705 Filesystem Escape","text":"<p>Jobs cannot access files outside their sandbox directory.</p> <pre><code># These will fail in sandbox:\nopen('/etc/passwd', 'r')           # Permission denied\nopen('/home/user/private.txt', 'r') # Not visible\n</code></pre>"},{"location":"security/#network-access","title":"\u2705 Network Access","text":"<p>Jobs cannot make network connections.</p> <pre><code># These will fail in sandbox:\nimport socket\nsocket.socket()  # Operation not permitted\n\nimport requests\nrequests.get('http://evil.com')  # No network\n</code></pre>"},{"location":"security/#process-interference","title":"\u2705 Process Interference","text":"<p>Jobs cannot see or interact with other processes.</p> <pre><code># These will fail in sandbox:\nimport os\nos.system('ps aux')  # Only sees own processes\nos.kill(1, 9)        # Cannot kill PID 1\n</code></pre>"},{"location":"security/#resource-exhaustion","title":"\u2705 Resource Exhaustion","text":"<p>Jobs cannot consume unlimited resources.</p> <pre><code># These will be killed:\nwhile True:\n    data.append([0] * 1000000)  # Exceeds memory limit\n\nimport os\nos.fork()  # Exceeds process limit\n</code></pre>"},{"location":"security/#data-persistence","title":"\u2705 Data Persistence","text":"<p>Job data automatically deleted after use.</p>"},{"location":"security/#what-sandrun-does-not-protect-against","title":"What Sandrun Does NOT Protect Against","text":""},{"location":"security/#kernel-vulnerabilities","title":"\u274c Kernel Vulnerabilities","text":"<p>If the Linux kernel has a vulnerability, sandbox escape is possible.</p> <p>Mitigation: Keep kernel updated with security patches.</p>"},{"location":"security/#timing-attacks","title":"\u274c Timing Attacks","text":"<p>Jobs sharing CPU cores could leak information via timing.</p> <p>Mitigation: Use dedicated hardware for sensitive workloads.</p>"},{"location":"security/#covert-channels","title":"\u274c Covert Channels","text":"<p>Advanced attacks (cache timing, speculative execution) could leak data.</p> <p>Mitigation: Not a concern for most use cases. Use dedicated hardware if needed.</p>"},{"location":"security/#physical-access","title":"\u274c Physical Access","text":"<p>Attacker with physical access can bypass all software security.</p> <p>Mitigation: Standard physical security measures.</p>"},{"location":"security/#deployment-best-practices","title":"Deployment Best Practices","text":""},{"location":"security/#system-hardening","title":"System Hardening","text":""},{"location":"security/#1-keep-system-updated","title":"1. Keep System Updated","text":"<pre><code># Ubuntu/Debian\nsudo apt-get update\nsudo apt-get upgrade -y\n\n# Check kernel version\nuname -r  # Should be recent version\n\n# Check for security updates\nsudo unattended-upgrade --dry-run\n</code></pre>"},{"location":"security/#2-use-security-modules","title":"2. Use Security Modules","text":"<p>Enable AppArmor or SELinux for additional protection:</p> <pre><code># AppArmor (Ubuntu/Debian)\nsudo apt-get install apparmor apparmor-utils\nsudo aa-status\n\n# SELinux (RHEL/Fedora)\nsestatus\n# Should show: SELinux status: enabled\n</code></pre>"},{"location":"security/#3-configure-firewall","title":"3. Configure Firewall","text":"<pre><code># Allow only necessary ports\nsudo ufw default deny incoming\nsudo ufw default allow outgoing\nsudo ufw allow 8443/tcp  # Sandrun API\nsudo ufw enable\n</code></pre>"},{"location":"security/#4-disable-unnecessary-services","title":"4. Disable Unnecessary Services","text":"<pre><code># List running services\nsystemctl list-units --type=service --state=running\n\n# Disable unnecessary services\nsudo systemctl disable bluetooth\nsudo systemctl disable cups\n</code></pre>"},{"location":"security/#network-security","title":"Network Security","text":""},{"location":"security/#use-tls-in-production","title":"Use TLS in Production","text":"<pre><code># Generate self-signed certificate (testing)\nopenssl req -x509 -newkey rsa:4096 -nodes \\\n  -keyout key.pem -out cert.pem -days 365\n\n# Start Sandrun with TLS\nsudo ./build/sandrun --port 8443 \\\n  --cert cert.pem --key key.pem\n</code></pre> <p>Production TLS</p> <p>Use Let's Encrypt or a commercial CA for production certificates. <pre><code>sudo certbot certonly --standalone -d sandrun.example.com\nsudo ./build/sandrun --port 8443 \\\n  --cert /etc/letsencrypt/live/sandrun.example.com/fullchain.pem \\\n  --key /etc/letsencrypt/live/sandrun.example.com/privkey.pem\n</code></pre></p>"},{"location":"security/#reverse-proxy-setup","title":"Reverse Proxy Setup","text":"<p>Use nginx or Caddy for TLS termination:</p> <pre><code># /etc/nginx/sites-available/sandrun\nserver {\n    listen 443 ssl http2;\n    server_name sandrun.example.com;\n\n    ssl_certificate /etc/letsencrypt/live/sandrun.example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/sandrun.example.com/privkey.pem;\n\n    # Security headers\n    add_header Strict-Transport-Security \"max-age=31536000\" always;\n    add_header X-Frame-Options DENY always;\n    add_header X-Content-Type-Options nosniff always;\n\n    location / {\n        proxy_pass http://localhost:8443;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    # WebSocket support\n    location /logs/ {\n        proxy_pass http://localhost:8443;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n}\n</code></pre>"},{"location":"security/#access-control","title":"Access Control","text":""},{"location":"security/#ip-allowlisting","title":"IP Allowlisting","text":"<pre><code># Restrict access to specific IPs\nlocation /submit {\n    allow 192.168.1.0/24;\n    allow 10.0.0.0/8;\n    deny all;\n\n    proxy_pass http://localhost:8443;\n}\n</code></pre>"},{"location":"security/#api-authentication-custom","title":"API Authentication (Custom)","text":"<p>While Sandrun doesn't include built-in authentication, you can add it via reverse proxy:</p> <pre><code># Basic auth with nginx\nlocation / {\n    auth_basic \"Sandrun API\";\n    auth_basic_user_file /etc/nginx/.htpasswd;\n    proxy_pass http://localhost:8443;\n}\n</code></pre> <p>Or use OAuth2 proxy: <pre><code># OAuth2 Proxy for Google/GitHub auth\ndocker run -p 4180:4180 \\\n  -e OAUTH2_PROXY_CLIENT_ID=xxx \\\n  -e OAUTH2_PROXY_CLIENT_SECRET=yyy \\\n  quay.io/oauth2-proxy/oauth2-proxy\n</code></pre></p>"},{"location":"security/#monitoring-logging","title":"Monitoring &amp; Logging","text":""},{"location":"security/#system-monitoring","title":"System Monitoring","text":"<pre><code># Monitor resource usage\nhtop\n\n# Check Sandrun logs\njournalctl -u sandrun -f\n\n# Monitor failed jobs\ntail -f /var/log/sandrun/errors.log\n</code></pre>"},{"location":"security/#intrusion-detection","title":"Intrusion Detection","text":"<pre><code># Install AIDE (file integrity monitoring)\nsudo apt-get install aide\nsudo aideinit\nsudo aide --check\n\n# Install fail2ban (rate limit enforcement)\nsudo apt-get install fail2ban\n</code></pre>"},{"location":"security/#prometheus-metrics-custom-integration","title":"Prometheus Metrics (Custom Integration)","text":"<p>Add metrics endpoint to track:</p> <ul> <li>Jobs submitted per minute</li> <li>CPU quota usage per IP</li> <li>Memory usage per job</li> <li>Job failure rates</li> <li>Queue depth</li> </ul>"},{"location":"security/#worker-identity-verification","title":"Worker Identity &amp; Verification","text":"<p>For pool deployments, use worker identity for result verification:</p>"},{"location":"security/#1-generate-worker-keypair","title":"1. Generate Worker Keypair","text":"<pre><code>sudo ./build/sandrun --generate-key /etc/sandrun/worker.pem\n\n# Output:\n# \u2705 Saved worker key to: /etc/sandrun/worker.pem\n#    Worker ID: &lt;base64-public-key&gt;\n</code></pre>"},{"location":"security/#2-secure-private-key","title":"2. Secure Private Key","text":"<pre><code># Restrict permissions\nsudo chmod 600 /etc/sandrun/worker.pem\nsudo chown root:root /etc/sandrun/worker.pem\n\n# Use dedicated key storage\n# - Hardware Security Module (HSM)\n# - AWS KMS\n# - HashiCorp Vault\n</code></pre>"},{"location":"security/#3-verify-results","title":"3. Verify Results","text":"<pre><code>import base64\nimport nacl.signing\n\n# Get job result\nresult = requests.get(f'http://pool:9000/status/{job_id}').json()\n\nworker_id = result['worker_metadata']['worker_id']\nsignature = result['worker_metadata']['signature']\njob_hash = result['job_hash']\n\n# Verify signature\nverify_key = nacl.signing.VerifyKey(base64.b64decode(worker_id))\ntry:\n    verify_key.verify(job_hash.encode(), base64.b64decode(signature))\n    print(\"\u2705 Result verified!\")\nexcept nacl.exceptions.BadSignatureError:\n    print(\"\u274c Invalid signature - result tampered!\")\n</code></pre>"},{"location":"security/#code-execution-safety","title":"Code Execution Safety","text":""},{"location":"security/#input-validation","title":"Input Validation","text":"<p>Always validate user inputs before submitting to Sandrun:</p> <pre><code>import json\nimport tarfile\n\ndef validate_manifest(manifest_json):\n    \"\"\"Validate manifest before submission\"\"\"\n    try:\n        manifest = json.loads(manifest_json)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON\")\n\n    # Required fields\n    if 'entrypoint' not in manifest:\n        raise ValueError(\"Missing entrypoint\")\n\n    # Validate timeout\n    timeout = manifest.get('timeout', 300)\n    if timeout &gt; 3600 or timeout &lt; 1:\n        raise ValueError(\"Invalid timeout\")\n\n    # Validate memory\n    memory_mb = manifest.get('memory_mb', 512)\n    if memory_mb &gt; 2048 or memory_mb &lt; 64:\n        raise ValueError(\"Invalid memory limit\")\n\n    return manifest\n\ndef validate_tarball(tarball_path):\n    \"\"\"Validate tarball before submission\"\"\"\n    try:\n        with tarfile.open(tarball_path, 'r:gz') as tar:\n            # Check file count\n            members = tar.getmembers()\n            if len(members) &gt; 1000:\n                raise ValueError(\"Too many files\")\n\n            # Check total size\n            total_size = sum(m.size for m in members)\n            if total_size &gt; 100 * 1024 * 1024:  # 100MB\n                raise ValueError(\"Tarball too large\")\n\n            # Check for path traversal\n            for member in members:\n                if member.name.startswith('/') or '..' in member.name:\n                    raise ValueError(\"Invalid file path\")\n\n    except tarfile.TarError:\n        raise ValueError(\"Invalid tarball\")\n</code></pre>"},{"location":"security/#sanitize-outputs","title":"Sanitize Outputs","text":"<p>Filter sensitive information from job outputs:</p> <pre><code>import re\n\ndef sanitize_logs(logs):\n    \"\"\"Remove sensitive data from logs\"\"\"\n    # Remove potential secrets\n    logs = re.sub(r'API_KEY=\\S+', 'API_KEY=***', logs)\n    logs = re.sub(r'password=\\S+', 'password=***', logs)\n    logs = re.sub(r'token:\\s*\\S+', 'token: ***', logs)\n\n    # Remove IP addresses\n    logs = re.sub(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', 'x.x.x.x', logs)\n\n    return logs\n</code></pre>"},{"location":"security/#incident-response","title":"Incident Response","text":""},{"location":"security/#detecting-compromises","title":"Detecting Compromises","text":"<p>Warning signs of potential compromise:</p> <ol> <li> <p>Unusual resource usage <pre><code># Check CPU usage\ntop -bn1 | head -20\n\n# Check memory\nfree -h\n\n# Check network connections (should be minimal)\nnetstat -tulpn\n</code></pre></p> </li> <li> <p>Suspicious job submissions</p> </li> <li>Very large tarballs</li> <li>Jobs with unusual interpreters</li> <li> <p>Rapid job submissions from single IP</p> </li> <li> <p>System logs <pre><code># Check kernel logs\ndmesg | tail -100\n\n# Check auth logs\ntail -f /var/log/auth.log\n\n# Check for failed namespace creation\njournalctl -k | grep namespace\n</code></pre></p> </li> </ol>"},{"location":"security/#response-procedures","title":"Response Procedures","text":"<p>If you suspect compromise:</p> <ol> <li> <p>Immediate Actions <pre><code># Stop Sandrun\nsudo systemctl stop sandrun\n\n# Kill all sandbox processes\nsudo pkill -9 -f sandrun\n\n# Check for running jobs\nps aux | grep sandbox\n</code></pre></p> </li> <li> <p>Investigation <pre><code># Collect system state\nps auxf &gt; /tmp/processes.txt\nnetstat -tulpn &gt; /tmp/netstat.txt\nlsof &gt; /tmp/open_files.txt\n\n# Check for kernel exploits\ndmesg &gt; /tmp/kernel.log\n</code></pre></p> </li> <li> <p>Recovery <pre><code># Update system\nsudo apt-get update\nsudo apt-get upgrade -y\n\n# Rebuild Sandrun from source\ngit pull\nrm -rf build\ncmake -B build\ncmake --build build\n\n# Restart with fresh configuration\nsudo systemctl start sandrun\n</code></pre></p> </li> </ol>"},{"location":"security/#security-checklist","title":"Security Checklist","text":"<p>Use this checklist for production deployments:</p> <ul> <li>[ ] System fully updated (kernel, packages)</li> <li>[ ] Firewall configured (only necessary ports open)</li> <li>[ ] TLS enabled with valid certificate</li> <li>[ ] Reverse proxy configured with security headers</li> <li>[ ] Monitoring and alerting configured</li> <li>[ ] Backup and recovery procedures documented</li> <li>[ ] Worker keys secured (if using pool)</li> <li>[ ] Access logs enabled and reviewed regularly</li> <li>[ ] Incident response plan documented</li> <li>[ ] Regular security audits scheduled</li> </ul>"},{"location":"security/#reporting-security-issues","title":"Reporting Security Issues","text":"<p>Found a security vulnerability? Do not open a public issue.</p> <ol> <li>Email security@sandrun.example.com</li> <li>Include:</li> <li>Description of vulnerability</li> <li>Steps to reproduce</li> <li>Impact assessment</li> <li> <p>Suggested fix (if any)</p> </li> <li> <p>Wait for response before public disclosure</p> </li> </ol> <p>We follow responsible disclosure and will:</p> <ul> <li>Acknowledge within 48 hours</li> <li>Provide fix timeline</li> <li>Credit reporters (if desired)</li> <li>Coordinate disclosure</li> </ul> <p>Questions about security? Contact us \u2192</p>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>Solutions to common issues and error messages.</p>"},{"location":"troubleshooting/#quick-diagnosis","title":"Quick Diagnosis","text":"<p>Start here to quickly identify your issue:</p> <pre><code># Check if Sandrun is running\nps aux | grep sandrun\n\n# Check if port is accessible\ncurl http://localhost:8443/\n\n# Check system resources\nfree -h\ndf -h\n\n# Check kernel support\ncat /proc/sys/kernel/seccomp  # Should be 2\nls /proc/self/ns/               # Should list namespaces\n\n# Check recent logs\njournalctl -u sandrun -n 50\n</code></pre>"},{"location":"troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"troubleshooting/#cmake-cannot-find-dependencies","title":"CMake Cannot Find Dependencies","text":"<p>Symptom: <pre><code>CMake Error: Could not find libseccomp\n</code></pre></p> <p>Solution:</p> Ubuntu/DebianFedora/RHELBuild from source <pre><code>sudo apt-get install -y \\\n  libseccomp-dev \\\n  libcap-dev \\\n  libssl-dev \\\n  pkg-config\n</code></pre> <pre><code>sudo dnf install -y \\\n  libseccomp-devel \\\n  libcap-devel \\\n  openssl-devel\n</code></pre> <pre><code># libseccomp\ngit clone https://github.com/seccomp/libseccomp\ncd libseccomp\n./autogen.sh\n./configure\nmake\nsudo make install\n</code></pre>"},{"location":"troubleshooting/#build-fails-with-compiler-errors","title":"Build Fails with Compiler Errors","text":"<p>Symptom: <pre><code>error: 'optional' is not a member of 'std'\n</code></pre></p> <p>Solution:</p> <pre><code># Check GCC version (need 7.0+)\ngcc --version\n\n# Update if needed (Ubuntu)\nsudo apt-get install g++-9\nexport CXX=g++-9\n\n# Clean and rebuild\nrm -rf build\ncmake -B build -DCMAKE_CXX_COMPILER=g++-9\ncmake --build build\n</code></pre>"},{"location":"troubleshooting/#cmake-version-too-old","title":"CMake Version Too Old","text":"<p>Symptom: <pre><code>CMake 3.10 or higher is required. You are running version 2.8\n</code></pre></p> <p>Solution:</p> <pre><code># Install latest CMake\nwget https://github.com/Kitware/CMake/releases/download/v3.25.0/cmake-3.25.0-linux-x86_64.sh\nchmod +x cmake-3.25.0-linux-x86_64.sh\nsudo ./cmake-3.25.0-linux-x86_64.sh --prefix=/usr/local --skip-license\n\n# Verify\ncmake --version\n</code></pre>"},{"location":"troubleshooting/#server-startup-issues","title":"Server Startup Issues","text":""},{"location":"troubleshooting/#permission-denied-creating-namespace","title":"Permission Denied Creating Namespace","text":"<p>Symptom: <pre><code>[ERROR] Failed to create namespace: Operation not permitted\n</code></pre></p> <p>Solutions:</p> Use sudoGrant capabilitiesCheck namespace support <pre><code>sudo ./build/sandrun --port 8443\n</code></pre> <pre><code>sudo setcap cap_sys_admin,cap_sys_chroot,cap_setuid,cap_setgid+ep ./build/sandrun\n./build/sandrun --port 8443\n</code></pre> <pre><code># Check if unprivileged user namespaces are enabled\ncat /proc/sys/kernel/unprivileged_userns_clone\n\n# Enable if disabled\nsudo sysctl -w kernel.unprivileged_userns_clone=1\n\n# Make permanent\necho 'kernel.unprivileged_userns_clone=1' | \\\n  sudo tee -a /etc/sysctl.conf\nsudo sysctl -p\n</code></pre>"},{"location":"troubleshooting/#port-already-in-use","title":"Port Already in Use","text":"<p>Symptom: <pre><code>[ERROR] Failed to bind to port 8443: Address already in use\n</code></pre></p> <p>Solutions:</p> <pre><code># Option 1: Find what's using the port\nsudo lsof -i :8443\nsudo netstat -tulpn | grep 8443\n\n# Option 2: Kill the process\nsudo kill &lt;PID&gt;\n\n# Option 3: Use different port\nsudo ./build/sandrun --port 9000\n\n# Option 4: Stop existing Sandrun instance\nsudo systemctl stop sandrun\n# or\nsudo pkill -f sandrun\n</code></pre>"},{"location":"troubleshooting/#seccomp-not-supported","title":"Seccomp Not Supported","text":"<p>Symptom: <pre><code>[ERROR] Seccomp not supported on this kernel\n</code></pre></p> <p>Solution:</p> <pre><code># Check seccomp support\ncat /proc/sys/kernel/seccomp\n# Should output: 2\n\n# If 0, rebuild kernel with CONFIG_SECCOMP=y\n# Or use a distribution with seccomp enabled\n\n# Check kernel version (need 4.6+)\nuname -r\n\n# Update kernel if needed\nsudo apt-get install linux-generic-hwe-20.04\nsudo reboot\n</code></pre>"},{"location":"troubleshooting/#cannot-open-worker-key-file","title":"Cannot Open Worker Key File","text":"<p>Symptom: <pre><code>[ERROR] Failed to open worker key: /etc/sandrun/worker.pem: No such file or directory\n</code></pre></p> <p>Solution:</p> <pre><code># Generate new worker key\nsudo mkdir -p /etc/sandrun\nsudo ./build/sandrun --generate-key /etc/sandrun/worker.pem\n\n# Or skip worker key if not using pools\nsudo ./build/sandrun --port 8443  # No --worker-key flag\n</code></pre>"},{"location":"troubleshooting/#job-submission-issues","title":"Job Submission Issues","text":""},{"location":"troubleshooting/#invalid-manifest","title":"Invalid Manifest","text":"<p>Symptom: <pre><code>{\n  \"error\": \"Invalid manifest\",\n  \"details\": \"Missing required field: entrypoint\"\n}\n</code></pre></p> <p>Solution:</p> <pre><code># Validate JSON syntax\necho '{\"entrypoint\":\"main.py\"}' | jq .\n\n# Minimum valid manifest\ncat &gt; manifest.json &lt;&lt;EOF\n{\n  \"entrypoint\": \"main.py\",\n  \"interpreter\": \"python3\"\n}\nEOF\n\n# Submit with manifest\ncurl -X POST http://localhost:8443/submit \\\n  -F \"files=@job.tar.gz\" \\\n  -F \"manifest=$(cat manifest.json)\"\n</code></pre>"},{"location":"troubleshooting/#tarball-too-large","title":"Tarball Too Large","text":"<p>Symptom: <pre><code>{\n  \"error\": \"Upload too large\",\n  \"details\": \"Maximum size: 100MB\"\n}\n</code></pre></p> <p>Solutions:</p> <pre><code># Check tarball size\nls -lh job.tar.gz\n\n# Compress better\ntar czf job.tar.gz --best my_project/\n\n# Remove unnecessary files\ntar czf job.tar.gz \\\n  --exclude='*.pyc' \\\n  --exclude='__pycache__' \\\n  --exclude='.git' \\\n  --exclude='node_modules' \\\n  my_project/\n\n# Split into multiple jobs if needed\n</code></pre>"},{"location":"troubleshooting/#files-missing-in-tarball","title":"Files Missing in Tarball","text":"<p>Symptom: Job fails with <code>FileNotFoundError: main.py</code></p> <p>Solution:</p> <pre><code># List tarball contents\ntar -tzf job.tar.gz\n\n# Ensure entrypoint is included\ntar -tzf job.tar.gz | grep main.py\n\n# Create tarball correctly\ncd project_directory\ntar czf ../job.tar.gz .\n# Not: tar czf job.tar.gz project_directory\n</code></pre>"},{"location":"troubleshooting/#rate-limit-exceeded","title":"Rate Limit Exceeded","text":"<p>Symptom: <pre><code>{\n  \"error\": \"Rate limit exceeded\",\n  \"reason\": \"CPU quota exhausted (10.2/10.0 seconds used)\",\n  \"retry_after\": 45\n}\n</code></pre></p> <p>Solutions:</p> <pre><code># Check your quota\ncurl http://localhost:8443/stats\n\n# Wait for quota to reset\nsleep 60\n\n# Optimize code to use less CPU\n# Split long jobs into smaller chunks\n# Use more efficient algorithms\n</code></pre>"},{"location":"troubleshooting/#job-execution-issues","title":"Job Execution Issues","text":""},{"location":"troubleshooting/#job-failed-with-exit-code-1","title":"Job Failed with Exit Code 1","text":"<p>Symptom: <pre><code>{\n  \"status\": \"failed\",\n  \"exit_code\": 1\n}\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Get full logs\ncurl http://localhost:8443/logs/job-abc123\n\n# Common causes:\n# - Syntax error in code\n# - Missing dependency\n# - File not found\n# - Permission error\n</code></pre> <p>Solutions:</p> <pre><code># Test locally first\ncd project_directory\npython3 main.py  # Test before submitting\n\n# Add debugging\ncat &gt; main.py &lt;&lt;EOF\nimport sys\nprint(\"Python version:\", sys.version)\nprint(\"Working directory:\", os.getcwd())\nprint(\"Files:\", os.listdir('.'))\n# ... your code ...\nEOF\n</code></pre>"},{"location":"troubleshooting/#job-killed-exit-code-137","title":"Job Killed (Exit Code 137)","text":"<p>Symptom: <pre><code>{\n  \"status\": \"failed\",\n  \"exit_code\": 137,\n  \"details\": \"Killed by signal 9\"\n}\n</code></pre></p> <p>Causes:</p> <ul> <li>Out of memory (exceeded 512MB limit)</li> <li>Timeout (exceeded 5 minute limit)</li> </ul> <p>Solutions:</p> <pre><code># Increase memory limit in manifest\ncat &gt; manifest.json &lt;&lt;EOF\n{\n  \"entrypoint\": \"main.py\",\n  \"memory_mb\": 1024\n}\nEOF\n\n# Increase timeout\ncat &gt; manifest.json &lt;&lt;EOF\n{\n  \"entrypoint\": \"main.py\",\n  \"timeout\": 600\n}\nEOF\n\n# Optimize memory usage\n# - Use generators instead of lists\n# - Process data in chunks\n# - Delete large objects when done\n</code></pre>"},{"location":"troubleshooting/#permission-denied-inside-sandbox","title":"Permission Denied Inside Sandbox","text":"<p>Symptom: <pre><code>PermissionError: [Errno 13] Permission denied: '/etc/passwd'\n</code></pre></p> <p>Explanation:</p> <p>This is expected behavior. The sandbox restricts access to:</p> <ul> <li>Host filesystem (only job directory accessible)</li> <li>Network (completely blocked)</li> <li>System files (<code>/etc</code>, <code>/proc</code>, <code>/sys</code> read-only)</li> </ul> <p>Solutions:</p> <pre><code># Copy needed files into job directory\ncp /etc/hosts my_project/hosts\ntar czf job.tar.gz my_project/\n\n# In your code, use relative paths\nwith open('hosts', 'r') as f:  # Not /etc/hosts\n    data = f.read()\n</code></pre>"},{"location":"troubleshooting/#import-errors-missing-dependencies","title":"Import Errors (Missing Dependencies)","text":"<p>Symptom: <pre><code>ModuleNotFoundError: No module named 'numpy'\n</code></pre></p> <p>Solutions:</p> Use requirements.txtUse pre-built environmentInclude dependencies in tarball <pre><code># Create requirements.txt\ncat &gt; requirements.txt &lt;&lt;EOF\nnumpy==1.24.0\npandas==1.5.0\nEOF\n\n# Add to manifest\ncat &gt; manifest.json &lt;&lt;EOF\n{\n  \"entrypoint\": \"main.py\",\n  \"requirements\": \"requirements.txt\"\n}\nEOF\n</code></pre> <pre><code># List available environments\ncurl http://localhost:8443/environments\n\n# Use in manifest\ncat &gt; manifest.json &lt;&lt;EOF\n{\n  \"entrypoint\": \"main.py\",\n  \"environment\": \"ml-basic\"\n}\nEOF\n</code></pre> <pre><code># Install to local directory\npip install -t ./libs numpy pandas\n\n# In your code\nimport sys\nsys.path.insert(0, './libs')\nimport numpy\n</code></pre>"},{"location":"troubleshooting/#job-stuck-in-queued-status","title":"Job Stuck in \"queued\" Status","text":"<p>Symptom: Job never starts executing.</p> <p>Diagnosis:</p> <pre><code># Check system stats\ncurl http://localhost:8443/stats\n\n# Response shows:\n# \"queue_length\": 10  # Many queued jobs\n# \"active_jobs\": 2    # System busy\n</code></pre> <p>Causes:</p> <ul> <li>Too many concurrent jobs (2 per IP limit)</li> <li>System overloaded</li> <li>No available workers (if using pool)</li> </ul> <p>Solutions:</p> <pre><code># Wait for active jobs to complete\n# Or cancel queued jobs if needed\n\n# Check worker health (pool deployments)\ncurl http://pool:9000/pool\n</code></pre>"},{"location":"troubleshooting/#cannot-download-output-files","title":"Cannot Download Output Files","text":"<p>Symptom: <pre><code>{\n  \"error\": \"Job not found or expired\"\n}\n</code></pre></p> <p>Causes:</p> <ul> <li>Job auto-deleted after 1 hour</li> <li>Already downloaded (immediate deletion)</li> <li>Job failed (deleted after 5 minutes)</li> </ul> <p>Solutions:</p> <pre><code># Download immediately after completion\n# Check status first\nSTATUS=$(curl -s http://localhost:8443/status/job-abc123 | jq -r '.status')\n\nif [ \"$STATUS\" = \"completed\" ]; then\n  curl http://localhost:8443/download/job-abc123/output.txt -o output.txt\nfi\n\n# Use WebSocket streaming to monitor completion\n</code></pre>"},{"location":"troubleshooting/#pool-coordinator-issues","title":"Pool Coordinator Issues","text":""},{"location":"troubleshooting/#no-available-workers","title":"No Available Workers","text":"<p>Symptom: <pre><code>WARNING:__main__:No available workers for job pool-xxx\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Check pool status\ncurl http://pool:9000/pool\n\n# Response shows:\n# \"healthy_workers\": 0\n</code></pre> <p>Causes:</p> <ul> <li>All workers offline</li> <li>Workers failed health check</li> <li>Workers at max capacity</li> </ul> <p>Solutions:</p> <pre><code># Check worker health directly\ncurl http://worker1:8443/health\n\n# Start more workers\nsudo ./build/sandrun --port 8443 --worker-key /etc/sandrun/worker.pem\n\n# Check worker logs\njournalctl -u sandrun -f\n\n# Verify workers.json configuration\ncat workers.json\n# Ensure worker IDs and endpoints are correct\n</code></pre>"},{"location":"troubleshooting/#worker-authentication-failed","title":"Worker Authentication Failed","text":"<p>Symptom: <pre><code>ERROR:__main__:Health check failed for worker: Invalid worker_id\n</code></pre></p> <p>Solution:</p> <pre><code># Regenerate worker key\nsudo ./build/sandrun --generate-key /etc/sandrun/worker.pem\n\n# Copy output Worker ID\n# Update workers.json with new worker_id\n\n# Restart worker\nsudo systemctl restart sandrun\n</code></pre>"},{"location":"troubleshooting/#jobs-stuck-in-pool-queue","title":"Jobs Stuck in Pool Queue","text":"<p>Symptom: Jobs never dispatched to workers.</p> <p>Diagnosis:</p> <pre><code># Check pool logs\njournalctl -u pool-coordinator -f\n\n# Check worker endpoints\nfor worker in worker1 worker2 worker3; do\n  echo \"Testing $worker:\"\n  curl http://$worker:8443/health\ndone\n</code></pre> <p>Solutions:</p> <pre><code># Verify network connectivity\nping worker1\ntelnet worker1 8443\n\n# Check firewall rules\nsudo iptables -L -n\n\n# Ensure workers are reachable from coordinator\n# Update workers.json with correct endpoints\n</code></pre>"},{"location":"troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"troubleshooting/#slow-job-execution","title":"Slow Job Execution","text":"<p>Diagnosis:</p> <pre><code># Check system load\nuptime\ntop\n\n# Check I/O wait\niostat -x 1\n\n# Check memory pressure\nfree -h\nvmstat 1\n</code></pre> <p>Solutions:</p> <pre><code># Increase system resources\n# Add more RAM\n# Use faster CPU\n# Add more workers for horizontal scaling\n\n# Optimize job code\n# Use compiled languages for CPU-intensive tasks\n# Minimize disk I/O\n# Use efficient algorithms\n</code></pre>"},{"location":"troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Diagnosis:</p> <pre><code># Check memory usage\nfree -h\n\n# Check tmpfs usage\ndf -h /dev/shm\nmount | grep tmpfs\n\n# Check per-process memory\nps aux --sort=-%mem | head -20\n</code></pre> <p>Solutions:</p> <pre><code># Increase system RAM\n# Reduce concurrent job limit\n# Reduce per-job memory limit\n# Optimize job code for memory efficiency\n\n# Clean up old jobs manually if needed\nsudo systemctl restart sandrun\n</code></pre>"},{"location":"troubleshooting/#debugging-tools","title":"Debugging Tools","text":""},{"location":"troubleshooting/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code># Build with debug symbols\ncmake -B build -DCMAKE_BUILD_TYPE=Debug\ncmake --build build\n\n# Run with verbose logging\nsudo ./build/sandrun --port 8443 --verbose\n\n# Or set environment variable\nexport SANDRUN_LOG_LEVEL=debug\nsudo -E ./build/sandrun --port 8443\n</code></pre>"},{"location":"troubleshooting/#use-gdb-for-crashes","title":"Use GDB for Crashes","text":"<pre><code># Build with debug symbols\ncmake -B build -DCMAKE_BUILD_TYPE=Debug\ncmake --build build\n\n# Run under GDB\nsudo gdb ./build/sandrun\n(gdb) run --port 8443\n# Wait for crash\n(gdb) backtrace\n(gdb) info locals\n</code></pre>"},{"location":"troubleshooting/#memory-leak-detection","title":"Memory Leak Detection","text":"<pre><code># Run with Valgrind\nsudo valgrind \\\n  --leak-check=full \\\n  --show-leak-kinds=all \\\n  --track-origins=yes \\\n  --verbose \\\n  --log-file=valgrind.log \\\n  ./build/sandrun --port 8443\n\n# Analyze results\ncat valgrind.log\n</code></pre>"},{"location":"troubleshooting/#network-debugging","title":"Network Debugging","text":"<pre><code># Monitor HTTP traffic\nsudo tcpdump -i any -nn -A port 8443\n\n# Or use Wireshark\nsudo wireshark\n\n# Test with verbose curl\ncurl -v http://localhost:8443/\n</code></pre>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you're still stuck:</p> <ol> <li> <p>Check logs: <pre><code>journalctl -u sandrun -n 100\ndmesg | tail -50\n</code></pre></p> </li> <li> <p>Gather system info: <pre><code>./build/sandrun --version\nuname -a\ncat /etc/os-release\n</code></pre></p> </li> <li> <p>Search existing issues: GitHub Issues</p> </li> <li> <p>Ask for help:</p> </li> <li>GitHub Discussions</li> <li> <p>Include: OS, kernel version, error messages, logs</p> </li> <li> <p>Report bugs:</p> </li> <li>File an issue</li> <li>Include: steps to reproduce, expected vs actual behavior</li> </ol> <p>Still need help? Open an issue \u2192</p>"},{"location":"development/building/","title":"Building Sandrun","text":"<p>Guide for building and developing Sandrun.</p>"},{"location":"development/building/#prerequisites","title":"Prerequisites","text":""},{"location":"development/building/#system-requirements","title":"System Requirements","text":"<ul> <li>OS: Linux (Ubuntu 20.04+, Debian 11+)</li> <li>Kernel: 4.6+ (for namespace support)</li> <li>RAM: 2GB minimum</li> <li>Disk: 500MB for build artifacts</li> </ul>"},{"location":"development/building/#dependencies","title":"Dependencies","text":"<pre><code># Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install -y \\\n  build-essential \\\n  cmake \\\n  libseccomp-dev \\\n  libcap-dev \\\n  libssl-dev \\\n  pkg-config \\\n  git\n\n# Optional: for testing\nsudo apt-get install -y \\\n  libgtest-dev \\\n  lcov \\\n  python3-pip\n\n# Optional: for documentation\npip3 install mkdocs-material\n</code></pre>"},{"location":"development/building/#building","title":"Building","text":""},{"location":"development/building/#standard-build","title":"Standard Build","text":"<pre><code># Configure\ncmake -B build\n\n# Build\ncmake --build build\n\n# Output: build/sandrun\n</code></pre>"},{"location":"development/building/#debug-build","title":"Debug Build","text":"<pre><code># Configure with debug symbols\ncmake -B build -DCMAKE_BUILD_TYPE=Debug\n\n# Build\ncmake --build build\n\n# Run with GDB\nsudo gdb ./build/sandrun\n</code></pre>"},{"location":"development/building/#release-build","title":"Release Build","text":"<pre><code># Configure with optimizations\ncmake -B build -DCMAKE_BUILD_TYPE=Release\n\n# Build\ncmake --build build\n\n# Output is optimized and stripped\n</code></pre>"},{"location":"development/building/#build-options","title":"Build Options","text":"<pre><code># Enable all warnings\ncmake -B build -DCMAKE_CXX_FLAGS=\"-Wall -Wextra -Wpedantic\"\n\n# Enable address sanitizer (debugging memory issues)\ncmake -B build -DCMAKE_CXX_FLAGS=\"-fsanitize=address\"\n\n# Static analysis\ncmake -B build -DCMAKE_CXX_CLANG_TIDY=clang-tidy\n</code></pre>"},{"location":"development/building/#running-tests","title":"Running Tests","text":""},{"location":"development/building/#unit-tests","title":"Unit Tests","text":"<pre><code># Build tests\ncmake -B build\ncmake --build build\n\n# Run unit tests\n./build/tests/unit_tests\n\n# Run with verbose output\n./build/tests/unit_tests --gtest_color=yes --gtest_output=xml:test_results.xml\n</code></pre>"},{"location":"development/building/#integration-tests","title":"Integration Tests","text":"<pre><code># Integration tests may require sudo\nsudo ./build/tests/integration_tests\n</code></pre>"},{"location":"development/building/#test-coverage","title":"Test Coverage","text":"<pre><code># Build with coverage\ncmake -B build-coverage -DCMAKE_BUILD_TYPE=Debug -DCMAKE_CXX_FLAGS=\"--coverage\"\ncmake --build build-coverage\n\n# Run tests\n./build-coverage/tests/unit_tests\n\n# Generate coverage report\nlcov --directory build-coverage --capture --output-file coverage.info\nlcov --remove coverage.info '/usr/*' '*/tests/*' --output-file coverage.info\ngenhtml coverage.info --output-directory coverage_report\n\n# View report\nfirefox coverage_report/index.html\n</code></pre>"},{"location":"development/building/#test-script","title":"Test Script","text":"<pre><code># Run all tests and generate coverage\n./scripts/run_tests.sh\n</code></pre>"},{"location":"development/building/#development-workflow","title":"Development Workflow","text":""},{"location":"development/building/#code-style","title":"Code Style","text":"<p>Follow Google C++ Style Guide:</p> <ul> <li>2-space indentation</li> <li>Snake_case for variables</li> <li>PascalCase for classes</li> <li>UPPER_CASE for constants</li> <li><code>#pragma once</code> for header guards</li> </ul>"},{"location":"development/building/#static-analysis","title":"Static Analysis","text":"<pre><code># clang-tidy\nclang-tidy src/*.cpp -- -std=c++17\n\n# cppcheck\ncppcheck --enable=all src/\n</code></pre>"},{"location":"development/building/#format-code","title":"Format Code","text":"<pre><code># clang-format\nfind src/ -name \"*.cpp\" -o -name \"*.h\" | xargs clang-format -i\n</code></pre>"},{"location":"development/building/#project-structure","title":"Project Structure","text":"<pre><code>sandrun/\n\u251c\u2500\u2500 CMakeLists.txt           Build configuration\n\u251c\u2500\u2500 src/                     C++ source code\n\u2502   \u251c\u2500\u2500 main.cpp            Entry point\n\u2502   \u251c\u2500\u2500 sandbox.{h,cpp}     Sandbox implementation\n\u2502   \u251c\u2500\u2500 http_server.{h,cpp} HTTP server\n\u2502   \u251c\u2500\u2500 job_executor.{h,cpp} Job execution\n\u2502   \u251c\u2500\u2500 worker_identity.{h,cpp} Ed25519 signing\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 tests/                   Test suite\n\u2502   \u251c\u2500\u2500 unit/               Unit tests\n\u2502   \u2514\u2500\u2500 integration/        Integration tests\n\u251c\u2500\u2500 integrations/            Integrations\n\u251c\u2500\u2500 docs/                    Documentation\n\u2514\u2500\u2500 scripts/                 Helper scripts\n</code></pre>"},{"location":"development/building/#debugging","title":"Debugging","text":""},{"location":"development/building/#common-issues","title":"Common Issues","text":"<p>Permission Denied:</p> <pre><code># Namespaces require root\nsudo ./build/sandrun --port 8443\n</code></pre> <p>Seccomp Errors:</p> <pre><code># Check kernel support\ncat /proc/sys/kernel/seccomp\n# Should output: 2\n\n# Run without seccomp (debugging only)\n# Edit src/sandbox.cpp to disable seccomp\n</code></pre> <p>Memory Leaks:</p> <pre><code># Run with valgrind\nsudo valgrind --leak-check=full ./build/sandrun --port 8443\n</code></pre>"},{"location":"development/building/#gdb-debugging","title":"GDB Debugging","text":"<pre><code># Build with debug symbols\ncmake -B build -DCMAKE_BUILD_TYPE=Debug\ncmake --build build\n\n# Run with GDB\nsudo gdb ./build/sandrun\n\n# GDB commands:\n(gdb) break main\n(gdb) run --port 8443\n(gdb) backtrace\n(gdb) print variable_name\n</code></pre>"},{"location":"development/building/#contributing","title":"Contributing","text":""},{"location":"development/building/#development-cycle","title":"Development Cycle","text":"<ol> <li>Create Feature Branch</li> </ol> <pre><code>git checkout -b feature/my-feature\n</code></pre> <ol> <li>Write Tests First (TDD)</li> </ol> <pre><code># Add test to tests/unit/test_myfeature.cpp\n# Run and verify it fails\n./build/tests/unit_tests --gtest_filter=MyFeatureTest.*\n</code></pre> <ol> <li>Implement Feature</li> </ol> <pre><code># Implement in src/\n# Run tests again\n./build/tests/unit_tests --gtest_filter=MyFeatureTest.*\n</code></pre> <ol> <li>Run All Tests</li> </ol> <pre><code>./scripts/run_tests.sh\n</code></pre> <ol> <li>Commit</li> </ol> <pre><code>git add -A\ngit commit -m \"feat: Add my feature\n\n- Implemented X\n- Added tests\n- Updated docs\"\n</code></pre> <ol> <li>Submit PR</li> </ol> <pre><code>git push origin feature/my-feature\n# Create pull request on GitHub\n</code></pre>"},{"location":"development/building/#code-review-checklist","title":"Code Review Checklist","text":"<ul> <li>\u2705 Tests pass</li> <li>\u2705 Code follows style guide</li> <li>\u2705 No memory leaks (valgrind clean)</li> <li>\u2705 Documentation updated</li> <li>\u2705 No compiler warnings</li> </ul>"},{"location":"development/building/#release-process","title":"Release Process","text":""},{"location":"development/building/#version-bumping","title":"Version Bumping","text":"<ol> <li>Update version in <code>CMakeLists.txt</code></li> <li>Update <code>CHANGELOG.md</code></li> <li>Tag release:</li> </ol> <pre><code>git tag -a v1.0.0 -m \"Release v1.0.0\"\ngit push origin v1.0.0\n</code></pre>"},{"location":"development/building/#building-release","title":"Building Release","text":"<pre><code># Clean build\nrm -rf build\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build\n\n# Create tarball\ntar czf sandrun-v1.0.0-linux-x86_64.tar.gz \\\n  build/sandrun \\\n  README.md \\\n  LICENSE\n</code></pre>"},{"location":"development/building/#cicd","title":"CI/CD","text":""},{"location":"development/building/#github-actions","title":"GitHub Actions","text":"<p>See <code>.github/workflows/</code> for CI configuration.</p> <p>Tests run automatically on: - Every push - Every pull request - Release tags</p>"},{"location":"development/building/#next-steps","title":"Next Steps","text":"<ul> <li>Testing Guide</li> <li>Architecture</li> <li>Contributing Guidelines</li> </ul>"},{"location":"development/testing/","title":"Testing Guide","text":"<p>Comprehensive guide to testing Sandrun.</p>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 unit/                    Unit tests\n\u2502   \u251c\u2500\u2500 test_file_utils.cpp\n\u2502   \u251c\u2500\u2500 test_worker_identity.cpp\n\u2502   \u251c\u2500\u2500 test_sandbox.cpp\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 integration/             Integration tests\n    \u251c\u2500\u2500 test_job_verification.cpp\n    \u251c\u2500\u2500 test_worker_signing.cpp\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#quick-start","title":"Quick Start","text":"<pre><code># Build and run all tests\n./scripts/run_tests.sh\n</code></pre>"},{"location":"development/testing/#unit-tests","title":"Unit Tests","text":"<pre><code># Build tests\ncmake --build build\n\n# Run all unit tests\n./build/tests/unit_tests\n\n# Run specific test suite\n./build/tests/unit_tests --gtest_filter=FileUtilsTest.*\n\n# Run specific test\n./build/tests/unit_tests --gtest_filter=FileUtilsTest.SHA256File\n</code></pre>"},{"location":"development/testing/#integration-tests","title":"Integration Tests","text":"<pre><code># Integration tests may require sudo\nsudo ./build/tests/integration_tests\n\n# Run specific integration test\nsudo ./build/tests/integration_tests --gtest_filter=JobVerificationTest.*\n</code></pre>"},{"location":"development/testing/#with-output","title":"With Output","text":"<pre><code># Verbose output\n./build/tests/unit_tests --gtest_color=yes\n\n# XML output (for CI)\n./build/tests/unit_tests --gtest_output=xml:test_results.xml\n</code></pre>"},{"location":"development/testing/#test-coverage","title":"Test Coverage","text":""},{"location":"development/testing/#generate-coverage-report","title":"Generate Coverage Report","text":"<pre><code># Build with coverage flags\ncmake -B build-coverage \\\n  -DCMAKE_BUILD_TYPE=Debug \\\n  -DCMAKE_CXX_FLAGS=\"--coverage\"\n\ncmake --build build-coverage\n\n# Run tests\n./build-coverage/tests/unit_tests\n./build-coverage/tests/integration_tests\n\n# Generate report\nlcov --directory build-coverage --capture --output-file coverage.info\nlcov --remove coverage.info '/usr/*' '*/tests/*' --output-file coverage.info\ngenhtml coverage.info --output-directory coverage_report\n\n# View report\nfirefox coverage_report/index.html\n</code></pre>"},{"location":"development/testing/#coverage-targets","title":"Coverage Targets","text":"<ul> <li>Critical paths: 100% (crypto, verification, sandbox)</li> <li>Core features: 90%+ (job execution, HTTP server)</li> <li>Overall: 80%+</li> </ul>"},{"location":"development/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"development/testing/#unit-test-example","title":"Unit Test Example","text":"<pre><code>#include &lt;gtest/gtest.h&gt;\n#include \"file_utils.h\"\n\nusing namespace sandrun;\n\nTEST(FileUtilsTest, SHA256File) {\n    // Create temporary file\n    std::string test_file = \"/tmp/test_sha256.txt\";\n    std::ofstream f(test_file);\n    f &lt;&lt; \"Hello, World!\";\n    f.close();\n\n    // Calculate hash\n    std::string hash = FileUtils::sha256_file(test_file);\n\n    // Verify against known SHA256\n    EXPECT_EQ(hash, \"dffd6021bb2bd5b0af676290809ec3a53191dd81c7f70a4b28688a362182986f\");\n\n    // Cleanup\n    std::remove(test_file.c_str());\n}\n\nTEST(FileUtilsTest, SHA256FileNotFound) {\n    std::string hash = FileUtils::sha256_file(\"/nonexistent/file.txt\");\n    EXPECT_EQ(hash, \"\");\n}\n</code></pre>"},{"location":"development/testing/#integration-test-example","title":"Integration Test Example","text":"<pre><code>#include &lt;gtest/gtest.h&gt;\n#include \"sandbox.h\"\n#include \"job_executor.h\"\n\nTEST(SandboxIntegrationTest, PythonExecution) {\n    // Create test job\n    Job job;\n    job.job_id = \"test-job-123\";\n    job.entrypoint = \"test.py\";\n    job.interpreter = \"python3\";\n    job.working_dir = \"/tmp/test_sandbox\";\n\n    // Create job files\n    std::filesystem::create_directories(job.working_dir);\n    std::ofstream script(job.working_dir + \"/test.py\");\n    script &lt;&lt; \"print('Test passed!')\";\n    script.close();\n\n    // Execute in sandbox\n    Sandbox sandbox;\n    JobResult result = sandbox.execute(job);\n\n    // Verify results\n    EXPECT_EQ(result.exit_code, 0);\n    EXPECT_TRUE(result.output.find(\"Test passed!\") != std::string::npos);\n\n    // Cleanup\n    std::filesystem::remove_all(job.working_dir);\n}\n</code></pre>"},{"location":"development/testing/#test-categories","title":"Test Categories","text":""},{"location":"development/testing/#1-unit-tests","title":"1. Unit Tests","text":"<p>File Utils (<code>test_file_utils.cpp</code>) - SHA256 hashing (35 tests) - File metadata extraction - Directory hashing - Glob pattern matching</p> <p>Worker Identity (<code>test_worker_identity.cpp</code>) - Keypair generation (30 tests) - PEM file I/O - Signing and verification - Tampering detection</p> <p>Sandbox (<code>test_sandbox.cpp</code>) - Namespace creation - Seccomp filtering - Resource limits - Cleanup</p>"},{"location":"development/testing/#2-integration-tests","title":"2. Integration Tests","text":"<p>Job Verification (<code>test_job_verification.cpp</code>) - End-to-end job hash calculation (19 tests) - Output file hashing - JSON response format - Verification workflows</p> <p>Worker Signing (<code>test_worker_signing.cpp</code>) - Job signature generation (20 tests) - Signature verification - Tampering detection - Cross-worker verification</p> <p>Pool Integration (<code>integrations/trusted-pool/test_pool.sh</code>) - Worker health checks - Job distribution - Status proxying - Output download</p>"},{"location":"development/testing/#test-data","title":"Test Data","text":""},{"location":"development/testing/#fixtures","title":"Fixtures","text":"<pre><code>class SandboxTestFixture : public ::testing::Test {\nprotected:\n    void SetUp() override {\n        // Create test environment\n        test_dir = \"/tmp/sandrun_test_\" + random_string();\n        std::filesystem::create_directories(test_dir);\n    }\n\n    void TearDown() override {\n        // Cleanup\n        std::filesystem::remove_all(test_dir);\n    }\n\n    std::string test_dir;\n};\n\nTEST_F(SandboxTestFixture, IsolatedExecution) {\n    // Test uses test_dir from fixture\n}\n</code></pre>"},{"location":"development/testing/#mock-data","title":"Mock Data","text":"<pre><code>// Mock job\nJob create_test_job() {\n    Job job;\n    job.job_id = \"test-abc123\";\n    job.entrypoint = \"main.py\";\n    job.interpreter = \"python3\";\n    job.timeout = 60;\n    job.memory_mb = 256;\n    return job;\n}\n</code></pre>"},{"location":"development/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"development/testing/#github-actions","title":"GitHub Actions","text":"<pre><code>name: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Install dependencies\n        run: |\n          sudo apt-get update\n          sudo apt-get install -y libseccomp-dev libcap-dev libssl-dev libgtest-dev\n\n      - name: Build\n        run: |\n          cmake -B build\n          cmake --build build\n\n      - name: Run tests\n        run: |\n          ./build/tests/unit_tests --gtest_output=xml:test_results.xml\n\n      - name: Upload results\n        uses: actions/upload-artifact@v3\n        with:\n          name: test-results\n          path: test_results.xml\n</code></pre>"},{"location":"development/testing/#performance-testing","title":"Performance Testing","text":""},{"location":"development/testing/#benchmarks","title":"Benchmarks","text":"<pre><code>#include &lt;benchmark/benchmark.h&gt;\n\nstatic void BM_SHA256(benchmark::State&amp; state) {\n    std::string data(state.range(0), 'x');\n\n    for (auto _ : state) {\n        FileUtils::sha256_string(data);\n    }\n\n    state.SetBytesProcessed(state.iterations() * data.size());\n}\n\nBENCHMARK(BM_SHA256)-&gt;Range(1&lt;&lt;10, 1&lt;&lt;20);  // 1KB to 1MB\n</code></pre>"},{"location":"development/testing/#load-testing","title":"Load Testing","text":"<pre><code># Concurrent job submissions\nfor i in {1..100}; do\n    curl -X POST http://localhost:8443/submit \\\n      -F \"files=@test.tar.gz\" \\\n      -F 'manifest={\"entrypoint\":\"test.py\"}' &amp;\ndone\n\nwait\n</code></pre>"},{"location":"development/testing/#debugging-failed-tests","title":"Debugging Failed Tests","text":""},{"location":"development/testing/#verbose-output","title":"Verbose Output","text":"<pre><code># Run with verbose flag\n./build/tests/unit_tests --gtest_color=yes --gtest_print_time=1\n</code></pre>"},{"location":"development/testing/#repeat-failed-test","title":"Repeat Failed Test","text":"<pre><code># Run specific failed test\n./build/tests/unit_tests --gtest_filter=FailedTest --gtest_repeat=10\n</code></pre>"},{"location":"development/testing/#valgrind-check","title":"Valgrind Check","text":"<pre><code># Check for memory leaks\nvalgrind --leak-check=full ./build/tests/unit_tests --gtest_filter=FailedTest\n</code></pre>"},{"location":"development/testing/#test-best-practices","title":"Test Best Practices","text":""},{"location":"development/testing/#1-test-behavior-not-implementation","title":"1. Test Behavior, Not Implementation","text":"<p>\u274c Bad: <pre><code>TEST(JobExecutorTest, UsesCorrectDataStructure) {\n    EXPECT_TRUE(executor.uses_vector());  // Testing implementation\n}\n</code></pre></p> <p>\u2705 Good: <pre><code>TEST(JobExecutorTest, ExecutesJobsInOrder) {\n    executor.submit(job1);\n    executor.submit(job2);\n    EXPECT_EQ(executor.next(), job1);  // Testing behavior\n}\n</code></pre></p>"},{"location":"development/testing/#2-isolated-tests","title":"2. Isolated Tests","text":"<p>Each test should be independent:</p> <pre><code>TEST(FileUtilsTest, Test1) {\n    // Create own temp file\n    // Test logic\n    // Clean up\n}\n\nTEST(FileUtilsTest, Test2) {\n    // Don't depend on Test1\n}\n</code></pre>"},{"location":"development/testing/#3-descriptive-names","title":"3. Descriptive Names","text":"<pre><code>// Good test names describe what they test\nTEST(SandboxTest, FailsWhenEntrypointMissing)\nTEST(SandboxTest, EnforcesMemoryLimit)\nTEST(SandboxTest, IsolatesNetworkAccess)\n</code></pre>"},{"location":"development/testing/#4-aaa-pattern","title":"4. AAA Pattern","text":"<pre><code>TEST(Example, DoSomething) {\n    // Arrange: Setup test data\n    Job job = create_test_job();\n\n    // Act: Perform action\n    Result result = execute(job);\n\n    // Assert: Verify outcome\n    EXPECT_EQ(result.exit_code, 0);\n}\n</code></pre>"},{"location":"development/testing/#next-steps","title":"Next Steps","text":"<ul> <li>Building Guide</li> <li>Architecture</li> <li>Contributing</li> </ul>"},{"location":"integrations/broker/","title":"Sandrun Broker - Simple Job Distribution","text":"<p>A lightweight job broker for distributing work across multiple sandrun nodes. No blockchain, no complexity - just a simple HTTP coordinator.</p>"},{"location":"integrations/broker/#architecture","title":"Architecture","text":"<pre><code>Client \u2192 Broker Server \u2192 Sandrun Nodes\n         (job queue)     (execute jobs)\n</code></pre>"},{"location":"integrations/broker/#quick-start","title":"Quick Start","text":""},{"location":"integrations/broker/#1-start-broker-server","title":"1. Start Broker Server","text":"<pre><code>cd server\npip install -r requirements.txt\npython broker.py --port 8000\n</code></pre>"},{"location":"integrations/broker/#2-start-sandrun-node-with-broker-client","title":"2. Start Sandrun Node with Broker Client","text":"<pre><code># Terminal 1: Start sandrun\nsudo sandrun --port 8443\n\n# Terminal 2: Connect to broker\ncd node_client\npython node.py --broker http://localhost:8000 --sandrun http://localhost:8443\n</code></pre>"},{"location":"integrations/broker/#3-submit-jobs","title":"3. Submit Jobs","text":"<pre><code>import requests\n\n# Submit job\nresponse = requests.post('http://localhost:8000/submit', json={\n    'code': 'print(\"Hello distributed world!\")',\n    'interpreter': 'python3',\n    'timeout': 60\n})\n\njob_id = response.json()['job_id']\n\n# Check status\nstatus = requests.get(f'http://localhost:8000/status/{job_id}')\nprint(status.json())\n\n# Get results\nresults = requests.get(f'http://localhost:8000/results/{job_id}')\nprint(results.json()['output'])\n</code></pre>"},{"location":"integrations/broker/#components","title":"Components","text":""},{"location":"integrations/broker/#broker-server-serverbrokerpy","title":"Broker Server (<code>server/broker.py</code>)","text":"<ul> <li>Maintains job queue in SQLite</li> <li>Tracks registered nodes</li> <li>Assigns jobs to available nodes</li> <li>Stores results temporarily</li> </ul>"},{"location":"integrations/broker/#node-client-node_clientnodepy","title":"Node Client (<code>node_client/node.py</code>)","text":"<ul> <li>Registers with broker</li> <li>Polls for available jobs</li> <li>Executes via local sandrun</li> <li>Returns results to broker</li> </ul>"},{"location":"integrations/broker/#api-endpoints","title":"API Endpoints","text":""},{"location":"integrations/broker/#broker-server","title":"Broker Server","text":"Endpoint Method Description <code>/submit</code> POST Submit new job <code>/status/{job_id}</code> GET Check job status <code>/results/{job_id}</code> GET Get job results <code>/nodes</code> GET List registered nodes <code>/register</code> POST Register node (internal) <code>/heartbeat</code> POST Node keepalive (internal) <code>/claim</code> POST Claim job (internal)"},{"location":"integrations/broker/#database-schema","title":"Database Schema","text":"<pre><code>-- Jobs table\nCREATE TABLE jobs (\n    id TEXT PRIMARY KEY,\n    code TEXT,\n    interpreter TEXT,\n    status TEXT,  -- 'pending', 'assigned', 'running', 'completed', 'failed'\n    node_id TEXT,\n    output TEXT,\n    error TEXT,\n    created_at TIMESTAMP,\n    completed_at TIMESTAMP\n);\n\n-- Nodes table\nCREATE TABLE nodes (\n    id TEXT PRIMARY KEY,\n    endpoint TEXT,\n    capabilities TEXT,  -- JSON\n    last_heartbeat TIMESTAMP,\n    jobs_completed INTEGER\n);\n</code></pre>"},{"location":"integrations/broker/#features","title":"Features","text":"<ul> <li>\u2705 Simple HTTP-based coordination</li> <li>\u2705 SQLite persistence (no external DB needed)</li> <li>\u2705 Automatic node failover</li> <li>\u2705 Basic load balancing</li> <li>\u2705 Result caching</li> <li>\u2705 No blockchain complexity</li> <li>\u2705 No cryptocurrency required</li> <li>\u2705 Works with existing sandrun</li> </ul>"},{"location":"integrations/broker/#configuration","title":"Configuration","text":""},{"location":"integrations/broker/#broker-server_1","title":"Broker Server","text":"<pre><code># server/config.py\nJOB_TIMEOUT = 300  # seconds\nRESULT_TTL = 3600  # seconds\nNODE_TIMEOUT = 60  # seconds before marking node dead\nMAX_RETRIES = 3\n</code></pre>"},{"location":"integrations/broker/#node-client","title":"Node Client","text":"<pre><code>// node_client/config.json\n{\n  \"broker_url\": \"http://localhost:8000\",\n  \"sandrun_url\": \"http://localhost:8443\",\n  \"poll_interval\": 5,\n  \"capabilities\": {\n    \"cpu_cores\": 4,\n    \"memory_gb\": 8,\n    \"gpu\": false,\n    \"interpreters\": [\"python3\", \"node\", \"bash\"]\n  }\n}\n</code></pre>"},{"location":"integrations/broker/#security-notes","title":"Security Notes","text":"<ul> <li>Broker should run behind HTTPS in production</li> <li>Use API keys for authentication (not implemented in demo)</li> <li>Sandrun provides the actual security isolation</li> <li>Broker is just a coordinator, not a security boundary</li> </ul>"},{"location":"integrations/broker/#future-enhancements-if-needed","title":"Future Enhancements (if needed)","text":"<ul> <li>[ ] Payment integration (Stripe/PayPal)</li> <li>[ ] Priority queues</li> <li>[ ] Geographic node selection</li> <li>[ ] Job result verification (multiple nodes)</li> <li>[ ] Web dashboard</li> <li>[ ] Metrics and monitoring</li> </ul>"},{"location":"integrations/mcp-server/","title":"Sandrun MCP Server","text":"<p>Give Claude (and other LLMs) the power to execute code safely!</p> <p>This MCP (Model Context Protocol) server allows AI assistants like Claude to execute Python, JavaScript, and Bash code in Sandrun's secure sandbox environment.</p>"},{"location":"integrations/mcp-server/#why-this-is-awesome","title":"Why This Is Awesome","text":""},{"location":"integrations/mcp-server/#for-users","title":"For Users:","text":"<ul> <li>Safe AI Code Execution: Claude can run code without risking your system</li> <li>Instant Results: LLM writes code \u2192 Sandrun executes \u2192 Results back to LLM</li> <li>No Docker Required: Lightweight Linux namespaces instead of containers</li> <li>Fair Resource Sharing: Built-in rate limiting and queuing</li> </ul>"},{"location":"integrations/mcp-server/#for-developers","title":"For Developers:","text":"<ul> <li>Drop-in Solution: Just add to Claude Desktop config</li> <li>Multiple Languages: Python, JavaScript/Node, Bash out of the box</li> <li>Async Support: Non-blocking execution with status polling</li> <li>Battle-Tested: Uses Sandrun's proven isolation</li> </ul>"},{"location":"integrations/mcp-server/#quick-start","title":"Quick Start","text":""},{"location":"integrations/mcp-server/#1-install-dependencies","title":"1. Install Dependencies","text":"<pre><code>cd integrations/mcp-server\npip install -e .\n</code></pre>"},{"location":"integrations/mcp-server/#2-start-sandrun","title":"2. Start Sandrun","text":"<pre><code># In terminal 1\nsudo ./build/sandrun --port 8443\n</code></pre>"},{"location":"integrations/mcp-server/#3-configure-claude-desktop","title":"3. Configure Claude Desktop","text":"<p>Add to <code>~/Library/Application Support/Claude/claude_desktop_config.json</code> (Mac) or <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> (Windows):</p> <pre><code>{\n  \"mcpServers\": {\n    \"sandrun\": {\n      \"command\": \"python3\",\n      \"args\": [\n        \"/path/to/sandrun/integrations/mcp-server/sandrun_mcp.py\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"integrations/mcp-server/#4-restart-claude-desktop","title":"4. Restart Claude Desktop","text":"<p>The MCP server will start automatically when Claude launches.</p>"},{"location":"integrations/mcp-server/#usage-examples","title":"Usage Examples","text":"<p>Once configured, you can ask Claude:</p>"},{"location":"integrations/mcp-server/#example-1-data-analysis","title":"Example 1: Data Analysis","text":"<pre><code>\"Can you analyze this list of numbers and tell me the mean, median, and mode?\"\n</code></pre> <p>Claude will use <code>execute_python</code> to run NumPy/statistics code and return results.</p>"},{"location":"integrations/mcp-server/#example-2-file-processing","title":"Example 2: File Processing","text":"<pre><code>\"I need to process this CSV data and extract unique values from column 3\"\n</code></pre> <p>Claude writes Python/pandas code, executes it, and shows you the results.</p>"},{"location":"integrations/mcp-server/#example-3-algorithm-implementation","title":"Example 3: Algorithm Implementation","text":"<pre><code>\"Implement the Sieve of Eratosthenes for finding primes up to 1000\"\n</code></pre> <p>Claude writes the code, runs it via Sandrun, and shows both code and output.</p>"},{"location":"integrations/mcp-server/#example-4-text-processing","title":"Example 4: Text Processing","text":"<pre><code>\"Use bash tools to count word frequencies in this text\"\n</code></pre> <p>Claude uses <code>execute_bash</code> with grep/awk/sort to process text.</p>"},{"location":"integrations/mcp-server/#available-tools","title":"Available Tools","text":"<p>The MCP server exposes these tools to the LLM:</p>"},{"location":"integrations/mcp-server/#execute_python","title":"<code>execute_python</code>","text":"<p>Execute Python code in a secure sandbox. - Input: Python code string - Output: stdout, stderr, exit code, metrics - Limits: 512MB RAM, 5min timeout, no network</p>"},{"location":"integrations/mcp-server/#execute_javascript","title":"<code>execute_javascript</code>","text":"<p>Execute JavaScript/Node.js code. - Same security and limits as Python</p>"},{"location":"integrations/mcp-server/#execute_bash","title":"<code>execute_bash</code>","text":"<p>Execute Bash commands/scripts. - Standard Unix tools available - Same isolation and limits</p>"},{"location":"integrations/mcp-server/#check_job_status","title":"<code>check_job_status</code>","text":"<p>Check status of a submitted job. - Returns: queued | running | completed | failed</p>"},{"location":"integrations/mcp-server/#get_job_logs","title":"<code>get_job_logs</code>","text":"<p>Get execution output for a job. - Returns: stdout and stderr</p>"},{"location":"integrations/mcp-server/#security-features","title":"Security Features","text":"<p>All code executes with: - \u2705 Namespace Isolation: Separate PID, network, mount namespaces - \u2705 No Network Access: Completely airgapped execution - \u2705 Resource Limits: 512MB RAM, 5 minute timeout - \u2705 Seccomp Filtering: Only ~60 safe syscalls allowed - \u2705 Auto-Cleanup: All data destroyed after execution - \u2705 Rate Limiting: 10 CPU-seconds per minute per IP</p>"},{"location":"integrations/mcp-server/#configuration","title":"Configuration","text":""},{"location":"integrations/mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>SANDRUN_URL</code>: Sandrun server URL (default: http://localhost:8443)</li> <li><code>SANDRUN_TIMEOUT</code>: Max wait time for jobs (default: 30 seconds)</li> </ul>"},{"location":"integrations/mcp-server/#custom-configuration","title":"Custom Configuration","text":"<p>Edit <code>sandrun_mcp.py</code> to customize: - Timeout values - Server URL - Tool descriptions - Response formatting</p>"},{"location":"integrations/mcp-server/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Claude       \u2502  \"Calculate fibonacci(100)\"\n\u2502 Desktop      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 MCP Protocol (stdio)\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 sandrun_mcp  \u2502  Translates to HTTP API calls\n\u2502 .py          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 HTTP REST\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Sandrun      \u2502  Executes in isolated sandbox\n\u2502 (C++ server) \u2502  Returns stdout/stderr\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"integrations/mcp-server/#troubleshooting","title":"Troubleshooting","text":""},{"location":"integrations/mcp-server/#connection-refused","title":"\"Connection refused\"","text":"<ul> <li>Make sure Sandrun is running: <code>sudo ./build/sandrun --port 8443</code></li> <li>Check firewall settings</li> </ul>"},{"location":"integrations/mcp-server/#job-timeout","title":"\"Job timeout\"","text":"<ul> <li>Increase <code>SANDRUN_TIMEOUT</code> for longer-running code</li> <li>Check if Sandrun is under heavy load</li> </ul>"},{"location":"integrations/mcp-server/#rate-limit-exceeded","title":"\"Rate limit exceeded\"","text":"<ul> <li>Too many requests from same IP</li> <li>Wait 1 minute or increase limits in Sandrun config</li> </ul>"},{"location":"integrations/mcp-server/#claude-doesnt-see-the-tools","title":"Claude doesn't see the tools","text":"<ul> <li>Check Claude Desktop config file syntax</li> <li>Restart Claude Desktop</li> <li>Check MCP server logs</li> </ul>"},{"location":"integrations/mcp-server/#development","title":"Development","text":""},{"location":"integrations/mcp-server/#running-standalone","title":"Running Standalone","text":"<pre><code># Test the MCP server directly\npython3 sandrun_mcp.py\n</code></pre> <p>Then interact via MCP protocol over stdin/stdout.</p>"},{"location":"integrations/mcp-server/#testing-tools","title":"Testing Tools","text":"<pre><code>import asyncio\nfrom sandrun_mcp import SandrunMCPServer\n\nasync def test():\n    server = SandrunMCPServer()\n    result = await server.execute_python(\"print('Hello!')\")\n    print(result)\n\nasyncio.run(test())\n</code></pre>"},{"location":"integrations/mcp-server/#use-cases","title":"Use Cases","text":""},{"location":"integrations/mcp-server/#1-code-learning","title":"1. Code Learning","text":"<p>Ask Claude to demonstrate algorithms, data structures, or language features with live execution.</p>"},{"location":"integrations/mcp-server/#2-data-analysis","title":"2. Data Analysis","text":"<p>Give Claude a dataset, ask for analysis, get immediate pandas/numpy results.</p>"},{"location":"integrations/mcp-server/#3-prototyping","title":"3. Prototyping","text":"<p>Quickly test ideas: \"Does this regex work?\" \"What's the output of this function?\"</p>"},{"location":"integrations/mcp-server/#4-teaching","title":"4. Teaching","text":"<p>Students can ask Claude questions and see working code examples executed.</p>"},{"location":"integrations/mcp-server/#5-debugging","title":"5. Debugging","text":"<p>\"Why isn't this code working?\" Claude can modify and test hypotheses.</p>"},{"location":"integrations/mcp-server/#comparison-to-alternatives","title":"Comparison to Alternatives","text":"Feature Sandrun MCP E2B Docker Cloud Functions Setup Time 1 min Account signup 5-10 min Account signup Cold Start &lt;100ms ~1s ~1s ~500ms Memory Overhead ~10MB ~50MB ~100MB Varies Network Isolation \u2705 \u274c Optional \u274c Cost Free Paid tiers Free Paid Privacy Complete Data sent to cloud Local Data sent to cloud"},{"location":"integrations/mcp-server/#contributing","title":"Contributing","text":"<p>Ideas for improvements: - Add more language support (Ruby, Go, Rust) - Streaming output support - File upload/download for multi-file projects - Custom resource limits per tool - Output visualization (plots, charts)</p>"},{"location":"integrations/mcp-server/#license","title":"License","text":"<p>Same as Sandrun main project (MIT).</p> <p>Now LLMs can safely execute code! \ud83c\udf89</p>"},{"location":"integrations/trusted-pool/","title":"Trusted Pool Coordinator","text":"<p>A simple pool coordinator that routes jobs to allowlisted workers. Workers are trusted based on their Ed25519 public keys.</p>"},{"location":"integrations/trusted-pool/#architecture","title":"Architecture","text":"<pre><code>Client \u2192 Pool Coordinator \u2192 Trusted Workers\n                \u2193\n         Allowlist (public keys)\n         Health checking\n         Load balancing\n</code></pre>"},{"location":"integrations/trusted-pool/#trust-model","title":"Trust Model","text":"<ul> <li>Workers are allowlisted by their Ed25519 public keys</li> <li>No result verification needed (trusted execution)</li> <li>Health checking ensures worker availability</li> <li>Load balancing distributes jobs across available workers</li> </ul> <p>This is simpler than the trustless pool because: - No consensus needed - No verification of results - No economic incentives (stake/slash) - Workers are pre-approved and trusted</p>"},{"location":"integrations/trusted-pool/#setup","title":"Setup","text":""},{"location":"integrations/trusted-pool/#1-install-dependencies","title":"1. Install Dependencies","text":"<pre><code>cd integrations/trusted-pool\npip install -r requirements.txt\n</code></pre>"},{"location":"integrations/trusted-pool/#2-configure-workers","title":"2. Configure Workers","text":"<p>Create <code>workers.json</code> with your trusted workers:</p> <pre><code>[\n  {\n    \"worker_id\": \"base64-encoded-ed25519-public-key\",\n    \"endpoint\": \"http://worker1.example.com:8443\",\n    \"max_concurrent_jobs\": 4\n  },\n  {\n    \"worker_id\": \"another-public-key-base64\",\n    \"endpoint\": \"http://worker2.example.com:8443\",\n    \"max_concurrent_jobs\": 4\n  }\n]\n</code></pre> <p>To get a worker's public key (worker_id):</p> <pre><code># On worker machine:\n./sandrun --generate-key /etc/sandrun/worker.pem\n\n# Output shows:\n# \u2705 Saved worker key to: /etc/sandrun/worker.pem\n#    Worker ID: &lt;base64-encoded-public-key&gt;\n</code></pre> <p>Add the worker ID to your <code>workers.json</code> allowlist.</p>"},{"location":"integrations/trusted-pool/#3-start-workers","title":"3. Start Workers","text":"<p>On each worker machine:</p> <pre><code>sudo ./sandrun --port 8443 --worker-key /etc/sandrun/worker.pem\n</code></pre>"},{"location":"integrations/trusted-pool/#4-start-pool-coordinator","title":"4. Start Pool Coordinator","text":"<pre><code>python coordinator.py --port 9000 --workers workers.json\n</code></pre>"},{"location":"integrations/trusted-pool/#usage","title":"Usage","text":""},{"location":"integrations/trusted-pool/#submit-job-to-pool","title":"Submit Job to Pool","text":"<p>Instead of submitting directly to a worker, submit to the pool coordinator:</p> <pre><code>curl -X POST http://pool.example.com:9000/submit \\\n  -F \"files=@project.tar.gz\" \\\n  -F 'manifest={\"entrypoint\":\"main.py\",\"interpreter\":\"python3\"}'\n</code></pre> <p>Response: <pre><code>{\n  \"job_id\": \"pool-a1b2c3d4e5f6\",\n  \"status\": \"queued\"\n}\n</code></pre></p>"},{"location":"integrations/trusted-pool/#check-job-status","title":"Check Job Status","text":"<pre><code>curl http://pool.example.com:9000/status/pool-a1b2c3d4e5f6\n</code></pre> <p>Response: <pre><code>{\n  \"job_id\": \"pool-a1b2c3d4e5f6\",\n  \"pool_status\": \"running\",\n  \"worker_id\": \"base64-worker-public-key\",\n  \"worker_status\": {\n    \"job_id\": \"remote-job-id-on-worker\",\n    \"status\": \"running\",\n    \"execution_metadata\": {\n      \"cpu_seconds\": 1.23,\n      \"memory_peak_bytes\": 52428800\n    }\n  },\n  \"submitted_at\": 1234567890.123,\n  \"completed_at\": null\n}\n</code></pre></p>"},{"location":"integrations/trusted-pool/#download-output","title":"Download Output","text":"<pre><code>curl http://pool.example.com:9000/outputs/pool-a1b2c3d4e5f6/results/output.png \\\n  -o output.png\n</code></pre>"},{"location":"integrations/trusted-pool/#check-pool-status","title":"Check Pool Status","text":"<pre><code>curl http://pool.example.com:9000/pool\n</code></pre> <p>Response: <pre><code>{\n  \"total_workers\": 3,\n  \"healthy_workers\": 2,\n  \"total_jobs\": 15,\n  \"queued_jobs\": 2,\n  \"workers\": [\n    {\n      \"worker_id\": \"worker-1-public-key\",\n      \"endpoint\": \"http://worker1.example.com:8443\",\n      \"is_healthy\": true,\n      \"active_jobs\": 3,\n      \"max_concurrent_jobs\": 4,\n      \"last_health_check\": 1234567890.123\n    }\n  ]\n}\n</code></pre></p>"},{"location":"integrations/trusted-pool/#api-endpoints","title":"API Endpoints","text":""},{"location":"integrations/trusted-pool/#post-submit","title":"POST /submit","text":"<p>Submit a job to the pool.</p> <p>Request: - <code>files</code>: Tarball of project files (multipart/form-data) - <code>manifest</code>: Job manifest JSON</p> <p>Response: <pre><code>{\n  \"job_id\": \"pool-xxx\",\n  \"status\": \"queued\"\n}\n</code></pre></p>"},{"location":"integrations/trusted-pool/#get-statusjob_id","title":"GET /status/{job_id}","text":"<p>Get job status.</p> <p>Response: <pre><code>{\n  \"job_id\": \"pool-xxx\",\n  \"pool_status\": \"running\",\n  \"worker_id\": \"worker-public-key\",\n  \"worker_status\": { ... },\n  \"submitted_at\": 1234567890.123,\n  \"completed_at\": null\n}\n</code></pre></p>"},{"location":"integrations/trusted-pool/#get-outputsjob_idpath","title":"GET /outputs/{job_id}/{path}","text":"<p>Download output file.</p> <p>Response: Binary file content</p>"},{"location":"integrations/trusted-pool/#get-pool","title":"GET /pool","text":"<p>Get pool status.</p> <p>Response: <pre><code>{\n  \"total_workers\": 3,\n  \"healthy_workers\": 2,\n  \"total_jobs\": 10,\n  \"queued_jobs\": 1,\n  \"workers\": [ ... ]\n}\n</code></pre></p>"},{"location":"integrations/trusted-pool/#how-it-works","title":"How It Works","text":""},{"location":"integrations/trusted-pool/#job-flow","title":"Job Flow","text":"<ol> <li>Client submits job to pool coordinator</li> <li>Job enters queue with \"queued\" status</li> <li>Coordinator finds available worker (healthy, not overloaded)</li> <li>Job dispatched to worker via HTTP POST to worker's /submit endpoint</li> <li>Worker executes job in sandbox</li> <li>Client polls status via pool coordinator (proxied to worker)</li> <li>Client downloads outputs via pool coordinator (proxied from worker)</li> </ol>"},{"location":"integrations/trusted-pool/#health-checking","title":"Health Checking","text":"<ul> <li>Pool coordinator checks each worker every 30 seconds</li> <li>Health check: <code>GET http://worker:8443/health</code></li> <li>Expected response: <code>{\"status\":\"healthy\",\"worker_id\":\"...\"}</code></li> <li>Unhealthy workers are excluded from routing</li> </ul>"},{"location":"integrations/trusted-pool/#load-balancing","title":"Load Balancing","text":"<ul> <li>Jobs routed to worker with fewest active jobs</li> <li>Workers have <code>max_concurrent_jobs</code> limit (default: 4)</li> <li>If no workers available, job waits in queue</li> </ul>"},{"location":"integrations/trusted-pool/#failure-handling","title":"Failure Handling","text":"<ul> <li>If worker rejects job \u2192 job re-queued</li> <li>If worker fails health check \u2192 marked unhealthy, excluded from routing</li> <li>Jobs in progress on failed workers remain assigned (client can retry)</li> </ul>"},{"location":"integrations/trusted-pool/#differences-from-trustless-pool","title":"Differences from Trustless Pool","text":"Feature Trusted Pool Trustless Pool Worker authorization Allowlist (public keys) Open (anyone can join) Result verification None (trust workers) Hash comparison + consensus Economic model None Stake + slashing Complexity Simple (~200 lines) Complex (~1000+ lines) Use case Private cluster, known workers Public compute, anonymous workers"},{"location":"integrations/trusted-pool/#security-considerations","title":"Security Considerations","text":""},{"location":"integrations/trusted-pool/#worker-authentication","title":"Worker Authentication","text":"<p>Workers must be started with <code>--worker-key</code> to have an identity. The pool coordinator verifies worker identity during health checks:</p> <pre><code>if data.get(\"worker_id\") == worker.worker_id:\n    worker.is_healthy = True\n</code></pre> <p>This prevents: - Impersonation: Rogue server can't pretend to be allowlisted worker - Unauthorized workers: Only allowlisted workers receive jobs</p>"},{"location":"integrations/trusted-pool/#network-security","title":"Network Security","text":"<p>Since this is a trusted pool, you should:</p> <ol> <li>Use private network or VPN for worker communication</li> <li>Enable TLS on workers (add HTTPS support)</li> <li>Firewall workers to only accept from coordinator IP</li> <li>Restrict pool coordinator to authorized clients</li> </ol>"},{"location":"integrations/trusted-pool/#resource-limits","title":"Resource Limits","text":"<p>Workers enforce their own resource limits (as configured in sandrun). The pool coordinator adds: - max_concurrent_jobs: Prevent worker overload - Job queueing: Prevent coordinator overload - Health checks: Detect and exclude failed workers</p>"},{"location":"integrations/trusted-pool/#monitoring","title":"Monitoring","text":""},{"location":"integrations/trusted-pool/#logs","title":"Logs","text":"<p>The coordinator logs: - Job submissions and dispatching - Worker health status changes - Errors and warnings</p> <p>Example: <pre><code>INFO:__main__:Added trusted worker: a1b2c3d4e5f6... at http://worker1:8443\nINFO:__main__:Queued job pool-abc123\nINFO:__main__:Dispatched job pool-abc123 to a1b2c3d4e5f6... (remote: job-xyz789)\nWARNING:__main__:Health check failed for b2c3d4e5f6g7...: Connection refused\n</code></pre></p>"},{"location":"integrations/trusted-pool/#metrics","title":"Metrics","text":"<p>Check <code>/pool</code> endpoint for real-time metrics: - Total workers and healthy count - Total jobs and queue depth - Per-worker active job count</p>"},{"location":"integrations/trusted-pool/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements for production use:</p> <ol> <li>Persistent storage for job history (currently in-memory)</li> <li>Worker capacity discovery (auto-detect max_concurrent_jobs)</li> <li>Job priority queues (high/low priority jobs)</li> <li>Authentication for clients (API keys, OAuth)</li> <li>TLS support for encrypted communication</li> <li>Metrics export (Prometheus, Grafana)</li> <li>Job cancellation (cancel in-progress jobs)</li> <li>Worker drain mode (stop accepting new jobs for maintenance)</li> </ol>"},{"location":"integrations/trusted-pool/#troubleshooting","title":"Troubleshooting","text":""},{"location":"integrations/trusted-pool/#no-workers-available","title":"No workers available","text":"<pre><code>WARNING:__main__:No available workers for job pool-xxx\n</code></pre> <p>Causes: - All workers unhealthy (check worker logs) - All workers at max capacity (check <code>/pool</code> endpoint) - Workers not started with <code>--worker-key</code></p> <p>Solution: - Start more workers - Increase <code>max_concurrent_jobs</code> per worker - Check worker health endpoints directly</p>"},{"location":"integrations/trusted-pool/#jobs-stuck-in-queued-status","title":"Jobs stuck in \"queued\" status","text":"<p>Causes: - No healthy workers available - Worker endpoints incorrect in workers.json</p> <p>Solution: - Check <code>/pool</code> endpoint for worker health status - Verify worker endpoints are reachable - Check worker logs for errors</p>"},{"location":"integrations/trusted-pool/#worker-rejected-job","title":"Worker rejected job","text":"<pre><code>ERROR:__main__:Worker a1b2c3d4... rejected job: 400\n</code></pre> <p>Causes: - Invalid manifest format - Files too large for worker - Worker resource limits exceeded</p> <p>Solution: - Check worker logs for specific error - Verify manifest is valid JSON - Reduce job size or increase worker limits</p>"},{"location":"integrations/trusted-pool/#example-deployment","title":"Example Deployment","text":""},{"location":"integrations/trusted-pool/#3-worker-pool","title":"3-Worker Pool","text":"<pre><code># Worker 1\nsudo ./sandrun --port 8443 --worker-key /etc/sandrun/worker1.pem\n\n# Worker 2\nsudo ./sandrun --port 8443 --worker-key /etc/sandrun/worker2.pem\n\n# Worker 3\nsudo ./sandrun --port 8443 --worker-key /etc/sandrun/worker3.pem\n\n# Coordinator\npython coordinator.py --port 9000 --workers workers.json\n</code></pre> <p>workers.json: <pre><code>[\n  {\n    \"worker_id\": \"worker1-public-key-from-generate-key\",\n    \"endpoint\": \"http://192.168.1.101:8443\",\n    \"max_concurrent_jobs\": 4\n  },\n  {\n    \"worker_id\": \"worker2-public-key-from-generate-key\",\n    \"endpoint\": \"http://192.168.1.102:8443\",\n    \"max_concurrent_jobs\": 4\n  },\n  {\n    \"worker_id\": \"worker3-public-key-from-generate-key\",\n    \"endpoint\": \"http://192.168.1.103:8443\",\n    \"max_concurrent_jobs\": 4\n  }\n]\n</code></pre></p> <p>Now you can submit jobs to the pool at <code>http://coordinator-ip:9000/submit</code> and they will be automatically distributed across the 3 workers!</p>"}]}